{"cells": [{"metadata": {"id": "e77e6100-6a91-48ac-a3f1-95c5340b6f1a"}, "cell_type": "code", "source": "'''\nLicensed Materials - Property of IBM\nIBM Maximo APM - Predictive Maintenance Insights On-Premises\nIBM Maximo APM - Predictive Maintenance Insights SaaS \n# IBM Maximo Application Suite \n\u00a9 Copyright IBM Corp. 2019,2020,2021 All Rights Reserved.\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n'''", "execution_count": null, "outputs": []}, {"metadata": {"id": "465be8c6-0492-4830-97aa-86c5cf398306"}, "cell_type": "markdown", "source": "# Maximo Predict - End of Life Curve Model Template"}, {"metadata": {"id": "6accabff-382b-4d72-973b-8db27ef4aeb9"}, "cell_type": "markdown", "source": "1. [Introduction](#introduction)\n2. [Install Maximo Predict SDK](#install-maximo-apm-pmi-sdk)\n3. [Setup the Model Training Pipeline](#setup-model-training-pipline)\n4. [Train the Model Instance](#train-model-instance)\n5. [Register the Trained Model Instance](#register-trained-model-instance)\n6. [Model Template Internals](#model-template-internals)"}, {"metadata": {"id": "94fb89f4-bb8f-47d0-beea-dde348630977"}, "cell_type": "markdown", "source": "<a id='introduction'></a>\n## Introduction\nStatistically, to evaluate mean life of assets, the sample mean or the average age method is acceptable if a big population has end-of-life information. But assets such as generators, transformers, reactors, cables, and so on, have a relatively long life up to and even beyond 40 years and generally there are very limited end-of-life failure data. This algorithm is designed to address this use case: to estimate mean life with limited end-of-life failure data. In fact, the proposed algorithm works best when fewer than 20% of the assets has end-of-life failure data.\n\nThis notebook predicts failure probability curve for a type of asset. In the challenges of asset health assessment, the asset failure probability and its expected remaining life are the key aspects to analyze the asset health status.\n\nThe Failure Probability Curve model uses statistics distribution to assess the failure probability versus year. This model has two methods:\n+ **Normal Distribution**: a small percentage of assets fail during the early life cycle, a few last beyond the average expected life span, but the majority fails within their mean life.\n+ **Weibull Distribution**:\n    \\begin{cases} f(x;\\lambda,k) =  \\frac{k}{\\lambda}\\left(\\frac{x}{\\lambda}\\right)^{k-1}e^{-(x/\\lambda)^{k}} & x\\geq0 ,\\\\ 0 & x<0, \\end{cases}\n    where k > 0 is the shape parameter and \u03bb > 0 is the scale parameter.\n    \nData requirement -\nThe Failure Probability Curve model works best when only small percentage of assets (<= 20%) is end-of-life with at least 10 assets.\nThe model may not work if 40% or more assets are end-of-life already. On the other side, the sample assets need to have at least two end-of-life.\nNote: In Maximo, end-of-life is defined by the ASSET.STATUSDATE when \"status\" is \"DECOMMISSIONED\" in Maximo."}, {"metadata": {"id": "aff123c3-62e3-4629-b56e-de72cb6b785b"}, "cell_type": "markdown", "source": "<a id=\"install-maximo-apm-pmi-sdk\"></a>\n## Install the Maximo Predict SDK"}, {"metadata": {"id": "c971db90-c781-480c-9196-766592549619"}, "cell_type": "markdown", "source": "\n\nYou will need follow 4 credentials to run the notebook. You can obtain first 3 credentials if you are admin on Maximo Predict UI.\n\n\nSteps -\n\n    APM_ID: Application Administration -> System Properties -> Filter -> Search PMIId -> Current Value (eg. b95ed774)\n    APM_API_BASEURL: Application Administration -> Integration -> End Points--> Searh for predict -> click search result PREDICTAPI -> URL (e.g https://predict-api.mas-pmidev1-predict.svc, note you just need first part of the url)\n    APM_API_KEY: Application Administration -> Go To Administration -> Copy key from user card (e.g. 6805t46gn3tef37pu0picpg9vcq3hsmamm1enc43), or Add API key for the user if API key does not exist.\n\nStep to get db2_certificate.pem:\n    login CP4D. Click Services->Instances. Click the Predict DB. Click \"Download SSL Certificate\" and save it to the file named as db2_certificate.pem. Then upload the db2_certificate.pem to the CP4D by click \"New data Asset\".\n\n"}, {"metadata": {"id": "14ec247934084a45819358a1dd2c71b0"}, "cell_type": "code", "source": "import json\nimport os\n  \n# Opening JSON file\n\nconfig_file='/project_data/data_asset/Predict_Envs.json'\n\nif  os.path.isfile(config_file):\n    f = open('/project_data/data_asset/Predict_Envs.json',)\n    data = json.load(f)\n    f.close()\n    os.environ['APM_ID'] = data['APM_ID']\n    os.environ['APM_API_BASEURL'] = data['APM_API_BASEURL']\n    os.environ['APM_API_KEY'] = data['APM_API_KEY']\nelse:\n    print('Please make sure the Predict_Envs.json is in the Data Assets')", "execution_count": 1, "outputs": []}, {"metadata": {"id": "b31aebeb2dcb44a5b190a08184741fab"}, "cell_type": "code", "source": "#Override the 3 credentials if needed.\n# %%capture\n# # @hidden_cell\n# %env APM_ID=***********\n# %env APM_API_BASEURL=**************\n# %env APM_API_KEY=**************\n", "execution_count": 2, "outputs": []}, {"metadata": {"id": "4b5324cd-04b3-4c4c-b632-568daef3f5e8"}, "cell_type": "code", "source": "import os\nos.environ['TRUST_PREDICT']= os.getenv('APM_API_BASEURL')[8:]\n#print(os.getenv('TRUST_PREDICT'))\n\n\nos.environ['SSL_VERIFY_APM'] = 'False'\nos.environ['SSL_VERIFY_AS'] = 'False'\nmonitor_url= \"https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net\"\nos.environ['isICP']='true'\nos.environ['REST_METADATA_URL']=monitor_url\nos.environ['REST_KPI_URL']=monitor_url", "execution_count": 3, "outputs": []}, {"metadata": {"id": "a4949d29-e4da-402c-8a83-4a26a69184e8"}, "cell_type": "markdown", "source": "Then, install the Maximo Predict SDK by using the `pip` command."}, {"metadata": {"id": "57e0116dc38a41f79298e3d4bdc2826e"}, "cell_type": "code", "source": "!pip uninstall -y pmlib", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Found existing installation: pmlib 8.8.1.dev4249\r\nUninstalling pmlib-8.8.1.dev4249:\r\n  Successfully uninstalled pmlib-8.8.1.dev4249\r\n", "name": "stdout"}]}, {"metadata": {"id": "a4d5203c-c8ad-40f5-9dc3-67e3684c5d8e", "scrolled": true}, "cell_type": "code", "source": "!pip install --trusted-host ${TRUST_PREDICT}  -U ${APM_API_BASEURL}/ibm/pmi/service/rest/ds/${APM_ID}/${APM_API_KEY}/lib/download?filename=pmlib", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Collecting https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/masdev/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/lib/download?filename=pmlib\n  Downloading https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/masdev/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/lib/download?filename=pmlib (156.6 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m156.6/156.6 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/watson_data_client-1.0.1-cp310-cp310-linux_x86_64.whl\nProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/mat-sdk-0.31.0.zip\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl\nProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl\nProcessing //tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl\nRequirement already satisfied: requests-futures==1.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.0.0)\nRequirement already satisfied: ibm_db_sa==0.3.8 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (0.3.8)\nRequirement already satisfied: ibm_db==3.1.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (3.1.3)\nRequirement already satisfied: sqlalchemy==1.4.39 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.4.39)\nRequirement already satisfied: numpy==1.23.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.23.1)\nRequirement already satisfied: pandas==1.4.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.4.3)\nRequirement already satisfied: requests==2.28.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (2.28.1)\nRequirement already satisfied: scikit-learn==1.1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.1.1)\nRequirement already satisfied: scipy==1.8.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.8.1)\nRequirement already satisfied: joblib==1.1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.1.1)\nRequirement already satisfied: xgboost==1.6.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (1.6.2)\nRequirement already satisfied: dill==0.3.5.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (0.3.5.1)\nRequirement already satisfied: scikeras==0.9.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (0.9.0)\nRequirement already satisfied: protobuf==3.19.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (3.19.1)\nRequirement already satisfied: pytz in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pmlib==8.8.1.dev4249) (2022.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pandas==1.4.3->pmlib==8.8.1.dev4249) (2.8.2)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests==2.28.1->pmlib==8.8.1.dev4249) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests==2.28.1->pmlib==8.8.1.dev4249) (1.26.11)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests==2.28.1->pmlib==8.8.1.dev4249) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from requests==2.28.1->pmlib==8.8.1.dev4249) (2022.12.7)\nRequirement already satisfied: packaging>=0.21 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from scikeras==0.9.0->pmlib==8.8.1.dev4249) (21.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from scikit-learn==1.1.1->pmlib==8.8.1.dev4249) (2.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from sqlalchemy==1.4.39->pmlib==8.8.1.dev4249) (1.1.1)\nRequirement already satisfied: aiohttp==3.8.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (3.8.1)\nRequirement already satisfied: nest_asyncio==1.5.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (1.5.5)\nRequirement already satisfied: plotly==5.4.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (5.4.0)\nRequirement already satisfied: shap==0.40.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (0.40.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (5.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (4.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (21.4.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from aiohttp==3.8.1->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (1.2.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from plotly==5.4.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (8.0.1)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from plotly==5.4.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (1.16.0)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from shap==0.40.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (4.64.0)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from shap==0.40.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (0.0.7)\nRequirement already satisfied: cloudpickle in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from shap==0.40.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (2.1.0)\nRequirement already satisfied: numba in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from shap==0.40.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (0.56.1)\nRequirement already satisfied: pillow==9.3.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (9.3.0)\nRequirement already satisfied: notebook==6.4.12 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (6.4.12)\nRequirement already satisfied: Flask in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.2.5)\nRequirement already satisfied: pymannkendall==1.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.2)\nRequirement already satisfied: jupyter==1.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1)\nRequirement already satisfied: werkzeug==2.2.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.2.3)\nRequirement already satisfied: ipython==8.10.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (8.10.0)\nRequirement already satisfied: graphviz==0.14 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.14)\nRequirement already satisfied: missingpy==0.2.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.0)\nRequirement already satisfied: ipywidgets==7.5.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (7.5.0)\nRequirement already satisfied: setuptools<=63.4.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (63.4.1)\nRequirement already satisfied: tabulate==0.9.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.9.0)\nRequirement already satisfied: pwlf==1.1.7 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.1.7)\nRequirement already satisfied: matplotlib<=3.6.0,>=3.5.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.5.2)\nRequirement already satisfied: statsmodels<=0.13.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.13.2)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.18.1)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.8.0)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.11.2)\nRequirement already satisfied: stack-data in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.0)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.1.6)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (5.1.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.0.39)\nRequirement already satisfied: traitlets>=5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (5.1.1)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.7.5)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.5.2)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (6.9.1)\nRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (5.3.0)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (6.2)\nRequirement already satisfied: pyzmq>=17 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (23.2.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (21.3.0)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.13.1)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.8.0)\nRequirement already satisfied: prometheus-client in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.14.1)\nRequirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.11.2)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.0.3)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (5)\nRequirement already satisfied: jupyter-client>=5.3.4 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (7.3.5)\nRequirement already satisfied: ipython-genutils in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.0)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: pyDOE>=0.3.8 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pwlf==1.1.7->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.3.8)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from werkzeug==2.2.3->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.1.1)\nRequirement already satisfied: ibm-watson-machine-learning in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.0.277)\nRequirement already satisfied: mlflow==1.30.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.30.0)\nRequirement already satisfied: starlette==0.25.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.25.0)\nRequirement already satisfied: alembic<2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.11.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (6.0)\nRequirement already satisfied: querystring-parser<2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.2.4)\nRequirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.11.3)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.1.32)\nRequirement already satisfied: docker<7,>=4.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (6.1.3)\nRequirement already satisfied: gunicorn<21 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (20.1.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.4)\nRequirement already satisfied: prometheus-flask-exporter<1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.22.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (8.0.4)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.17.7)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.4.4)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from starlette==0.25.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.7.1)\nRequirement already satisfied: outlier-utils==0.0.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.0.3)\nRequirement already satisfied: networkx<=2.8.6,>=2.8.4 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.8.4)\nRequirement already satisfied: lightgbm==3.3.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.3.2)\nRequirement already satisfied: lifelines==0.14.6 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.14.6)\nRequirement already satisfied: imbalanced-learn==0.7.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.7.0)\nRequirement already satisfied: retrying==1.3.3 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.3.3)\nRequirement already satisfied: wheel<0.39,>=0.38.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from srom@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/srom-1.8.17.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.38.4)\nRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from Flask->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.1.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from matplotlib<=3.6.0,>=3.5.2->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from matplotlib<=3.6.0,>=3.5.2->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from matplotlib<=3.6.0,>=3.5.2->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from matplotlib<=3.6.0,>=3.5.2->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.4.2)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from statsmodels<=0.13.2->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.5.2)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ibm-watson-machine-learning->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.3.3)\nRequirement already satisfied: ibm-cos-sdk==2.12.* in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ibm-watson-machine-learning->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.12.0)\nRequirement already satisfied: jmespath<1.0.0,>=0.10.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.10.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.12.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.12.0)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from alembic<2->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.3.0)\nRequirement already satisfied: Mako in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from alembic<2->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.2.4)\nRequirement already satisfied: exceptiongroup in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.25.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.1.2)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.25.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.3.0)\nRequirement already satisfied: pyjwt>=1.7.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.4.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.2.1)\nRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.6.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from gitpython<4,>=2.1.0->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.0.10)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (3.8.0)\nRequirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.5.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.8.3)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from nbformat>=4.2.0->ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (4.4.0)\nRequirement already satisfied: fastjsonschema in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from nbformat>=4.2.0->ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.16.2)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.5)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from argon2-cffi->notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (21.2.0)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from numba->shap==0.40.0->aixclient@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/aixclient-1.5.0-pre.issue-167.zip->pmlib==8.8.1.dev4249) (0.39.0)\nRequirement already satisfied: executing in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from stack-data->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.8.3)\nRequirement already satisfied: asttokens in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from stack-data->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.0.5)\nRequirement already satisfied: pure-eval in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from stack-data->ipython==8.10.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==1.30.0->modelfactory@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/modelfactory-0.0.23.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (5.0.0)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.0->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (0.18.0)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/envs/Python-3.10-Premium/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.4.12->dqlearn@ file://localhost//tmp/1000800000/pip-req-build-iagnxk81/dslib/dqlearn-0.6.4.1.0-cp310-cp310-linux_x86_64.whl->pmlib==8.8.1.dev4249) (2.21)\ndqlearn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nwatson-data-client is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nmodelfactory is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nsrom is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nBuilding wheels for collected packages: pmlib, aixclient, mat-sdk\n  Building wheel for pmlib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pmlib: filename=pmlib-8.8.1.dev4249-py3-none-any.whl size=972581 sha256=4c70ce9687d052467fc72cb5241fa43dc9ce8542ec088bbdae204c221a16a3c4\n  Stored in directory: /tmp/1000800000/pip-ephem-wheel-cache-umqj5tc3/wheels/0c/f6/88/388c6421d8ce6b9f0a544ef416beb8824660d109b9f6babc58\n  Building wheel for aixclient (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for aixclient: filename=aixclient-1.5.0.dev389-py3-none-any.whl size=9739 sha256=09980d8c27b340e7e05069895efb925c1227c6d32f544aa6d4828683a1046d7d\n  Stored in directory: /tmp/1000800000/.cache/pip/wheels/4e/3d/b6/f7c968d771f5cc0b14e033eff9684968028fa175f85235441c\n  Building wheel for mat-sdk (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mat-sdk: filename=mat_sdk-0.31.0-py3-none-any.whl size=26638 sha256=3bd0ffd0dec5322ae1c257b16a7b9e7600cd3714248c3bc6a2b5f76333486ba7\n  Stored in directory: /tmp/1000800000/.cache/pip/wheels/4d/89/2e/cd2147059419eca913e89f8ab2cfdee335fafdb5fb4f727204\nSuccessfully built pmlib aixclient mat-sdk\nInstalling collected packages: mat-sdk, aixclient, pmlib\n  Attempting uninstall: mat-sdk\n    Found existing installation: mat-sdk 0.31.0\n    Uninstalling mat-sdk-0.31.0:\n      Successfully uninstalled mat-sdk-0.31.0\n  Attempting uninstall: aixclient\n    Found existing installation: aixclient 1.5.0.dev389\n    Uninstalling aixclient-1.5.0.dev389:\n      Successfully uninstalled aixclient-1.5.0.dev389\nSuccessfully installed aixclient-1.5.0.dev389 mat-sdk-0.31.0 pmlib-8.8.1.dev4249\n", "name": "stdout"}]}, {"metadata": {"id": "f1d33d1b-625c-48e4-a11d-c67379c8cf30"}, "cell_type": "markdown", "source": "<a id=\"setup-model-training-pipline\"></a>\n## Set up the model training pipeline"}, {"metadata": {"id": "6b3fd860-673a-4640-8f14-2347f0d14888"}, "cell_type": "markdown", "source": "Before you can start working on the model training pipeline, you have to set up an asset group properly in Maximo. See the IBM Maximo APM - Predictive Maintenance Insights SaaS documentation for details.\n\nRequired model pipeline configuration:\n\n* Asset group ID: The unit of model processing is an asset group. Asset groups are managed on the IBM Maximo Health->Predict grouping page. Get the ID of the asset group to be analyzed by this model.\n* Asset installation date and decommission date as the label: This model requires asset installation date (asset attribute **```installdate```** in Maximo) and asset decommission date (asset attribute **```ASSET.STATUSDATE when \"status\" is \"DECOMMISSIONED\"```** in Maximo) to extract the label for training.\n\nNow you can set up a training pipeine based on this model template, with your own data, to train a model instance."}, {"metadata": {"id": "7f47f393-185d-4a2d-b5da-7a11fa722763"}, "cell_type": "markdown", "source": "The preceding example configured a pipeline for this model using asset attributes **```installdate```** and **```ASSET.STATUSDATE when \"status\" is \"DECOMMISSIONED\"```** to extract the labels for training. This model only generates the failure probability curve and does not do scoring, hence no predictions are defined."}, {"metadata": {"id": "53b7b8c443b14a5582c3024317c3109d"}, "cell_type": "code", "source": "# you can get asset_group_id from Health's 'Predict grouping' page.\nasset_group_id='1002'", "execution_count": 6, "outputs": []}, {"metadata": {"id": "7db6797d-4f3e-4bf6-b958-ae542c31a9ce"}, "cell_type": "code", "source": "from pmlib.degradation_curve import DegradationCurveAssetGroupPipeline\n\ngroup = DegradationCurveAssetGroupPipeline(\n            asset_group_id=asset_group_id, \n            model_pipeline={\n                'missing_value_analysis': False,  # skip missing value analysis\n                \n                \"statistics_distribution_args\": {\n                    \"distribution_type\": \"WEIBULL\", \n                    \"mean_or_scale\": None,\n                    \"stddev_or_shape\": None\n                }\n            })", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Warning: confluent_kafka is not installed. Publish to MessageHub not supported.\n", "name": "stderr"}, {"output_type": "stream", "text": "2023-07-24T12:45:46.149 INFO::pmlib.util.setup_logging: Log level has not been set yet... setting to default level of 10\n2023-07-24T12:45:46.158 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Initializing End of Life Curve Asset Group Pipeline...\n2023-07-24T12:45:46.159 INFO::pmlib.api.init_environ: Initializing environment...\n2023-07-24T12:45:46.159 DEBUG::pmlib.api.init_environ: APM_ID=masdev, APM_API_BASEURL=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc, APM_API_KEY=********\n2023-07-24T12:45:46.160 DEBUG::pmlib.util.api_request: Making API Request: method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/tenant?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json=None, session=None, kwargs={}\n2023-07-24T12:45:46.632 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/tenant?instanceId=masdev\n2023-07-24T12:45:46.634 DEBUG::pmlib.api.init_environ: resp={\n    \"as_apikey\": \"********\",\n    \"as_apitoken\": \"********\",\n    \"as_id\": null,\n    \"as_url\": \"https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net\",\n    \"info\": {\n        \"API_BASEURL\": \"https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net\",\n        \"API_KEY\": \"********\",\n        \"API_TOKEN\": \"********\",\n        \"DB_CERTIFICATE_FILE\": \"/project_data/data_asset/db2_certificate.pem\",\n        \"DB_CONNECTION_STRING\": \"********\",\n        \"DB_TYPE\": \"db2\",\n        \"PMI_CLOUD_TYPE\": \"PUBLIC\",\n        \"SSL_VERIFY_APM\": \"false\",\n        \"SSL_VERIFY_AS\": \"false\",\n        \"TENANT_ID\": \"masdev\"\n    },\n    \"keyverified\": \"false\",\n    \"mahi_apikey\": null,\n    \"mahi_auth_url\": \"https://masocp-igki4x-masdev.mas-masocp-igki4x-manage.svc/maximo/api/permission/allowedappoptions?app=RELENGINEER&lean=1&ccm=1\",\n    \"mahi_id\": \"masdev\",\n    \"mahi_url\": \"https://masocp-igki4x-masdev.mas-masocp-igki4x-manage.svc/maximo\",\n    \"mas_as_schema\": \"MASDEV_MAM\",\n    \"mas_intg_status\": \"COMPLETE\",\n    \"tenant_as_id\": \"masdev\",\n    \"tenant_id\": \"1\",\n    \"tenant_mahi_id\": null,\n    \"tenant_name\": \"masdev\",\n    \"wml_cred\": \"********\"\n}\n2023-07-24T12:45:46.635 DEBUG::pmlib.api.init_environ: setting environment variable MAXIMO_BASEURL=https://masocp-igki4x-masdev.mas-masocp-igki4x-manage.svc/maximo\n2023-07-24T12:45:46.636 DEBUG::pmlib.api.init_environ: setting environment variable MAXIMO_API_CONTEXT=/api\n2023-07-24T12:45:46.636 DEBUG::pmlib.api.init_environ: setting environment variable AS_SCHEMA=MASDEV_MAM\n2023-07-24T12:45:46.637 DEBUG::pmlib.api.init_environ: setting environment variable SSL_VERIFY_APM=False\n2023-07-24T12:45:46.638 DEBUG::pmlib.api.init_environ: setting environment variable SSL_VERIFY_AS=False\n2023-07-24T12:45:46.639 DEBUG::pmlib.api.init_environ: setting environment variable SSL_VERIFY_WIOTP=False\n2023-07-24T12:45:46.639 DEBUG::pmlib.api.init_environ: setting environment variable SSL_VERIFY_MAXIMO=False\n2023-07-24T12:45:46.640 DEBUG::pmlib.api.init_environ: setting environment variable WML_VCAPS={\"instance_id\": \"openshift\", \"version\": \"4.6\", \"url\": \"https://internal-nginx-svc.ibm-cpd.svc:12443\"}\n2023-07-24T12:45:46.640 DEBUG::pmlib.api.init_environ: setting environment variable DB_CONNECTION_STRING=********\n2023-07-24T12:45:46.641 DEBUG::pmlib.api.init_environ: setting environment variable API_TOKEN=********\n2023-07-24T12:45:46.641 DEBUG::pmlib.api.init_environ: setting environment variable DB_TYPE=db2\n2023-07-24T12:45:46.642 DEBUG::pmlib.api.init_environ: setting environment variable API_KEY=********\n2023-07-24T12:45:46.642 DEBUG::pmlib.api.init_environ: setting environment variable PMI_CLOUD_TYPE=PUBLIC\n2023-07-24T12:45:46.643 DEBUG::pmlib.api.init_environ: setting environment variable API_BASEURL=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net\n2023-07-24T12:45:46.644 DEBUG::pmlib.api.init_environ: setting environment variable TENANT_ID=masdev\n2023-07-24T12:45:46.645 DEBUG::pmlib.api.init_environ: setting environment variable DB_CERTIFICATE_FILE=/project_data/data_asset/db2_certificate.pem\n2023-07-24T12:45:46.646 DEBUG::pmlib.util.api_request: Making API Request: method=put, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/constants/v1/masdev, headers={'Content-Type': 'application/json', 'X-api-key': '********', 'X-api-token': '********', 'Cache-Control': 'no-cache'}, timeout=300, ssl_verify=False, json=[{'name': 'apm_info', 'entityType': None, 'enabled': True, 'value': {'APM_ID': 'masdev', 'APM_API_BASEURL': 'https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc', 'APM_API_KEY': '********'}, 'metadata': {'type': 'CONSTANT', 'dataType': 'LITERAL', 'description': 'APM tenant information.', 'tags': None, 'required': True, 'values': None}}], session=None, kwargs={}\n2023-07-24T12:45:46.898 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=put, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/constants/v1/masdev\n2023-07-24T12:45:46.899 INFO::pmlib.api.init_environ: Finished initializing environment.\n2023-07-24T12:45:46.900 DEBUG::pmlib.api._get_db: Request made to retrieve DB...\n2023-07-24T12:45:46.901 DEBUG::pmlib.api._get_db: Database Type: db2\n2023-07-24T12:45:50.072 DEBUG::pmlib.api._get_db: Retrieved db.model_store.entity_type_id=None\n2023-07-24T12:45:50.073 DEBUG::pmlib.api._get_db: Successfully retrieved DB2 database\n2023-07-24T12:45:50.128 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Initializing ModelPipelineConfig Dict with the following parameters: features=[], features_for_training=['installdate', 'statusdate', 'status'], predictions=[], features_resampled={}, inputs=(':installdate', ':statusdate', ':status'), renamed_inputs=('installdate', 'statusdate', 'status')\n2023-07-24T12:45:50.129 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Added kwargs to ModelPipelineConfig: {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T12:45:50.130 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_pipeline_config: Subclass's prepared_model_config: {'features': [], 'features_for_training': ['installdate', 'statusdate', 'status'], 'targets': ['installdate', 'statusdate', 'status'], 'predictions': [], 'features_resampled': {}, 'inputs': (':installdate', ':statusdate', ':status'), 'renamed_inputs': ('installdate', 'statusdate', 'status'), 'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T12:45:50.131 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_latest_prediction_timestamp: Retrieved prediction table name: None\n2023-07-24T12:45:50.132 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Pipeline configuration: {'asset_group_id': '1002', 'model_pipeline': {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}, 'features_for_training': [':installdate', ':statusdate', ':status']}, 'incremental_summary': False, 'fillna': None, 'fillna_exclude': None, 'dropna': None, 'dropna_exclude': None, 'local_model': False}\n2023-07-24T12:45:50.132 DEBUG::pmlib.loader.AssetLoader._validate_data_items: Retrieved entity types from Monitor. all_entity_types={'ROBOT', 'Sample_boiler_type_template', 'tempsensor', 'Basic_templated', 'Basic_template'}\n2023-07-24T12:45:50.133 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Validating asset device mappings...\n2023-07-24T12:45:50.134 DEBUG::pmlib.loader.AssetLoader._set_asset_device_mappings: Set asset device mappings: input_asset_device_mappings=None, asset_device_mappings={}, entity_type_meta={}\n2023-07-24T12:45:50.135 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._prepare_published_outputs: Preparing published outputs. Input published_outputs={}\n2023-07-24T12:45:50.136 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._prepare_published_outputs: Finished preparing published outputs: {}\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T12:45:50.137 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Retrieved post processing configuration: post_processing=[]\n2023-07-24T12:45:50.137 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Incremental summary enabled: incremental_summary=False\n2023-07-24T12:45:50.138 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Retrieved published outputs: published_outputs={}\n2023-07-24T12:45:50.138 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._validate_pipeline_outputs: Validating pipeline outputs: current_outputs=[]\n2023-07-24T12:45:50.139 DEBUG::pmlib.util.api_request: Making API Request: method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/model/?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json=None, session=None, kwargs={}\n2023-07-24T12:45:50.640 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/model/?instanceId=masdev\n2023-07-24T12:45:50.642 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._validate_pipeline_outputs: Finished validating pipeline outputs. No issus detected.\n2023-07-24T12:45:50.643 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.__init__: Finished initializing Asset Group Pipeline.\n", "name": "stdout"}]}, {"metadata": {"id": "9d5468c2-7e19-4ee1-ae8d-0f1a57d0553c"}, "cell_type": "markdown", "source": "<a id=\"train-model-instance\"></a>\n## Train the model instance\n\nNow you can train the model instance."}, {"metadata": {"id": "3af4f4b4-174e-475b-9fe8-35e907ea254a"}, "cell_type": "code", "source": "df = group.execute()", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "2023-07-24T13:03:02.273 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: Starting execution of End of Life Curve Asset Group Pipeline...\n2023-07-24T13:03:02.274 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: Received input DataFrame: df=None\n2023-07-24T13:03:02.275 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Initializing ModelPipelineConfig Dict with the following parameters: features=[], features_for_training=['installdate', 'statusdate', 'status'], predictions=[], features_resampled={}, inputs=(':installdate', ':statusdate', ':status'), renamed_inputs=('installdate', 'statusdate', 'status')\n2023-07-24T13:03:02.276 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Added kwargs to ModelPipelineConfig: {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:02.277 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_pipeline_config: Subclass's prepared_model_config: {'features': [], 'features_for_training': ['installdate', 'statusdate', 'status'], 'targets': ['installdate', 'statusdate', 'status'], 'predictions': [], 'features_resampled': {}, 'inputs': (':installdate', ':statusdate', ':status'), 'renamed_inputs': ('installdate', 'statusdate', 'status'), 'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:02.278 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_latest_prediction_timestamp: Retrieved prediction table name: None\n2023-07-24T13:03:02.278 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: Initializing Asset Loader.\n2023-07-24T13:03:02.279 DEBUG::pmlib.loader.AssetLoader._validate_data_items: Retrieved entity types from Monitor. all_entity_types={'ROBOT', 'Sample_boiler_type_template', 'tempsensor', 'Basic_templated', 'Basic_template'}\n2023-07-24T13:03:02.280 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Validating asset device mappings...\n2023-07-24T13:03:02.281 DEBUG::pmlib.loader.AssetLoader._set_asset_device_mappings: Set asset device mappings: input_asset_device_mappings=None, asset_device_mappings={}, entity_type_meta={}\n2023-07-24T13:03:02.282 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Initializing ModelPipelineConfig Dict with the following parameters: features=[], features_for_training=['installdate', 'statusdate', 'status'], predictions=[], features_resampled={}, inputs=(':installdate', ':statusdate', ':status'), renamed_inputs=('installdate', 'statusdate', 'status')\n2023-07-24T13:03:02.282 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Added kwargs to ModelPipelineConfig: {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:02.283 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_pipeline_config: Subclass's prepared_model_config: {'features': [], 'features_for_training': ['installdate', 'statusdate', 'status'], 'targets': ['installdate', 'statusdate', 'status'], 'predictions': [], 'features_resampled': {}, 'inputs': (':installdate', ':statusdate', ':status'), 'renamed_inputs': ('installdate', 'statusdate', 'status'), 'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:02.283 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_latest_prediction_timestamp: Retrieved prediction table name: None\n2023-07-24T13:03:02.284 INFO::pmlib.cache_loader.AssetCacheRefresher.execute: Refreshing asset cache with data from Maximo and Monitor to update Predict database.\n2023-07-24T13:03:02.284 DEBUG::pmlib.cache_loader.AssetCacheRefresher.execute: Args: start_ts=None, end_ts=None, entities=None\n2023-07-24T13:03:02.285 DEBUG::pmlib.api._refresh_asset_cache: Refreshing asset cache. Args: asset_group_id=1002, data_items=[':installdate', ':statusdate', ':status']\n2023-07-24T13:03:02.286 DEBUG::pmlib.api._get_asset_group_table: Getting asset group table...\n2023-07-24T13:03:02.287 INFO::pmlib.api._get_asset_device_mapping_table: Retrieving asset device mapping table...\n2023-07-24T13:03:02.287 DEBUG::pmlib.api._get_asset_device_mapping_table: DB Schema to use: MASDEV_MAM\n2023-07-24T13:03:02.288 INFO::pmlib.api._get_asset_device_mapping_table: Successfully retrieved asset device mapping table.\n2023-07-24T13:03:02.289 INFO::pmlib.api.create_entity_type: Creating new entity type with name ASSET_CACHE...\n2023-07-24T13:03:02.290 DEBUG::pmlib.util.api_request: Making API Request: method=get, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/meta/v1/masdev/entityType/ASSET_CACHE, headers={'Content-Type': 'application/json', 'X-api-key': '********', 'X-api-token': '********', 'Cache-Control': 'no-cache'}, timeout=300, ssl_verify=False, json=None, session=None, kwargs={}\n2023-07-24T13:03:02.510 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=get, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/meta/v1/masdev/entityType/ASSET_CACHE\n2023-07-24T13:03:02.512 INFO::pmlib.api.create_entity_type: Entity type was automatically created from WIOTP device type=ASSET_CACHE\n2023-07-24T13:03:02.512 DEBUG::pmlib.api.create_entity_type: Getting entity type new table name from Monitor. Request body json={'search': 'ASSET_CACHE'}\n2023-07-24T13:03:02.513 DEBUG::pmlib.api._call_as_v2: Calling Monitor with V2 Protocol.\n2023-07-24T13:03:02.514 DEBUG::pmlib.api._call_as_v2: Monitor V2 call JSON={'search': 'ASSET_CACHE'}\n2023-07-24T13:03:02.515 DEBUG::pmlib.api._call_as_v2: Monitor V2 call URL=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/v2/core/deviceTypes/search?status=ACTIVE&offset=0&limit=100\n2023-07-24T13:03:02.516 DEBUG::pmlib.util.api_request: Making API Request: method=post, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/v2/core/deviceTypes/search?status=ACTIVE&offset=0&limit=100, headers={'Content-Type': 'application/json', 'X-api-key': '********', 'X-api-token': '********', 'Cache-Control': 'no-cache', 'tenantId': 'masdev', 'mam_user_email': 'ibm@ibm.com'}, timeout=300, ssl_verify=False, json={'search': 'ASSET_CACHE'}, session=None, kwargs={}\n2023-07-24T13:03:02.693 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=post, url=https://masdev.api.monitor.masocp-igki4x.apps.masocp-igki4x.ibmazsp.net/api/v2/core/deviceTypes/search?status=ACTIVE&offset=0&limit=100\n2023-07-24T13:03:02.695 DEBUG::pmlib.api._get_entity_type_table_name_from_monitor: entity type table name: IOT_ASSET_CACHE_6\n2023-07-24T13:03:02.696 DEBUG::pmlib.api.create_entity_type: Retrieved new table name. new_table_name=IOT_ASSET_CACHE_6\n2023-07-24T13:03:02.696 INFO::pmlib.api.create_entity_type: Successfully created new entity type: entity_type=APM_ASSET_CACHE\n2023-07-24T13:03:02.697 DEBUG::pmlib.util.api_request: Making API Request: method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/devicemapping?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json=None, session=None, kwargs={}\n2023-07-24T13:03:03.215 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/devicemapping?instanceId=masdev\n2023-07-24T13:03:03.217 DEBUG::pmlib.api.get_maximo_asset_device_mappings: Call get_maximo_asset_device_mappings resp: {\"1002\":[{\"devices\":[],\"assetNum\":\"ROBOARM1\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM2\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM3\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM4\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM5\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM6\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM7\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM8\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM9\",\"siteId\":\"BEDFORD\"}]}\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T13:03:03.218 DEBUG::pmlib.api._refresh_asset_cache: Retrieved asset device mappings for asset group id 1002. Mappings=[{'devices': [], 'assetNum': 'ROBOARM1', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM2', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM3', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM4', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM5', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM6', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM7', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM8', 'siteId': 'BEDFORD'}, {'devices': [], 'assetNum': 'ROBOARM9', 'siteId': 'BEDFORD'}]\n2023-07-24T13:03:03.218 DEBUG::pmlib.api._refresh_asset_cache: Generating device list... iterating over data_items: [':installdate', ':statusdate', ':status']\n2023-07-24T13:03:03.219 DEBUG::pmlib.api._refresh_asset_cache: Iterating over data items. Current name_type: \n2023-07-24T13:03:03.220 DEBUG::pmlib.api._refresh_asset_cache: Iterating over data items. Current name_type: \n2023-07-24T13:03:03.220 DEBUG::pmlib.api._refresh_asset_cache: Iterating over data items. Current name_type: \n2023-07-24T13:03:03.221 DEBUG::pmlib.api._refresh_asset_cache: Generated device types list: []\n2023-07-24T13:03:03.222 DEBUG::pmlib.api._refresh_asset_cache: No asset device mappings in Maximo... calling new Monitor Data Dictionary API to get asset device mapping\n2023-07-24T13:03:03.223 DEBUG::pmlib.api._refresh_asset_cache: Updated asset device mappings: []\n2023-07-24T13:03:03.226 DEBUG::pmlib.api._refresh_asset_cache: Retrieved all assets of the given asset group: df_asset_group_members=\n=========== START DATAFRAME LOG ===========\nshape=(9, 4), \nindex={0: 'int64'}, \ncolumns={'assetgroup': 'O', 'site': 'O', 'asset': 'O', 'assetid': 'O'}, \nhead(5)=\n  assetgroup     site     asset                assetid\n0       1002  BEDFORD  ROBOARM1  ROBOARM1-____-BEDFORD\n1       1002  BEDFORD  ROBOARM2  ROBOARM2-____-BEDFORD\n2       1002  BEDFORD  ROBOARM3  ROBOARM3-____-BEDFORD\n3       1002  BEDFORD  ROBOARM4  ROBOARM4-____-BEDFORD\n4       1002  BEDFORD  ROBOARM5  ROBOARM5-____-BEDFORD\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.246 INFO::pmlib.loader.AssetLoader.execute: Executing asset loader. Args: start_ts=None, end_ts=None, entities=None, df_input=None\n2023-07-24T13:03:03.247 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Loading asset device mappings...\n2023-07-24T13:03:03.247 DEBUG::pmlib.api._get_asset_group_table: Getting asset group table...\n2023-07-24T13:03:03.248 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Query AHI for asset device mappings: SQL Query=SELECT \"MASDEV_MAM\".apm_asset_groups.site, \"MASDEV_MAM\".apm_asset_groups.asset, \"MASDEV_MAM\".apm_asset_device_attributes.devicetype, \"MASDEV_MAM\".apm_asset_device_attributes.deviceid \nFROM \"MASDEV_MAM\".apm_asset_groups LEFT OUTER JOIN \"MASDEV_MAM\".apm_asset_device_attributes ON \"MASDEV_MAM\".apm_asset_device_attributes.site = \"MASDEV_MAM\".apm_asset_groups.site AND \"MASDEV_MAM\".apm_asset_device_attributes.asset = \"MASDEV_MAM\".apm_asset_groups.asset \nWHERE \"MASDEV_MAM\".apm_asset_groups.assetgroup = ?\n2023-07-24T13:03:03.256 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Query results: df_ahi_mappings=\n=========== START DATAFRAME LOG ===========\nshape=(9, 4), \nindex={0: 'int64'}, \ncolumns={'site': 'O', 'asset': 'O', 'devicetype': 'O', 'deviceid': 'O'}, \nhead(5)=\n      site     asset devicetype deviceid\n0  BEDFORD  ROBOARM1       None     None\n1  BEDFORD  ROBOARM2       None     None\n2  BEDFORD  ROBOARM3       None     None\n3  BEDFORD  ROBOARM4       None     None\n4  BEDFORD  ROBOARM5       None     None\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.259 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Update DF with asset full ID: df_ahi_mappings=\n=========== START DATAFRAME LOG ===========\nshape=(9, 5), \nindex={0: 'int64'}, \ncolumns={'site': 'O', 'asset': 'O', 'devicetype': 'O', 'deviceid': 'O', 'assetfullid': 'O'}, \nhead(5)=\n      site     asset devicetype deviceid            assetfullid\n0  BEDFORD  ROBOARM1       None     None  ROBOARM1-____-BEDFORD\n1  BEDFORD  ROBOARM2       None     None  ROBOARM2-____-BEDFORD\n2  BEDFORD  ROBOARM3       None     None  ROBOARM3-____-BEDFORD\n3  BEDFORD  ROBOARM4       None     None  ROBOARM4-____-BEDFORD\n4  BEDFORD  ROBOARM5       None     None  ROBOARM5-____-BEDFORD\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.260 INFO::pmlib.api._get_asset_device_mapping_table: Retrieving asset device mapping table...\n2023-07-24T13:03:03.261 DEBUG::pmlib.api._get_asset_device_mapping_table: DB Schema to use: MASDEV_MAM\n2023-07-24T13:03:03.261 INFO::pmlib.api._get_asset_device_mapping_table: Successfully retrieved asset device mapping table.\n2023-07-24T13:03:03.263 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Query PMI for asset device mappings: SQL Query=SELECT \"MASDEV_MAM\".apm_asset_groups.site, \"MASDEV_MAM\".apm_asset_groups.asset, \"MASDEV_MAM\".apm_asset_devices.devicetype, \"MASDEV_MAM\".apm_asset_devices.deviceid \nFROM \"MASDEV_MAM\".apm_asset_groups LEFT OUTER JOIN \"MASDEV_MAM\".apm_asset_devices ON \"MASDEV_MAM\".apm_asset_devices.site = \"MASDEV_MAM\".apm_asset_groups.site AND \"MASDEV_MAM\".apm_asset_devices.asset = \"MASDEV_MAM\".apm_asset_groups.asset \nWHERE \"MASDEV_MAM\".apm_asset_groups.assetgroup = ?\n2023-07-24T13:03:03.270 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Query results:  df_pmi_mappings=\n=========== START DATAFRAME LOG ===========\nshape=(9, 4), \nindex={0: 'int64'}, \ncolumns={'site': 'O', 'asset': 'O', 'devicetype': 'O', 'deviceid': 'O'}, \nhead(5)=\n      site     asset devicetype deviceid\n0  BEDFORD  ROBOARM1       None     None\n1  BEDFORD  ROBOARM2       None     None\n2  BEDFORD  ROBOARM3       None     None\n3  BEDFORD  ROBOARM4       None     None\n4  BEDFORD  ROBOARM5       None     None\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.274 DEBUG::pmlib.loader.AssetLoader._load_asset_device_mappings: Updated DF with asset full ID: df_pmi_mappings=\n=========== START DATAFRAME LOG ===========\nshape=(9, 5), \nindex={0: 'int64'}, \ncolumns={'site': 'O', 'asset': 'O', 'devicetype': 'O', 'deviceid': 'O', 'assetfullid': 'O'}, \nhead(5)=\n      site     asset devicetype deviceid            assetfullid\n0  BEDFORD  ROBOARM1       None     None  ROBOARM1-____-BEDFORD\n1  BEDFORD  ROBOARM2       None     None  ROBOARM2-____-BEDFORD\n2  BEDFORD  ROBOARM3       None     None  ROBOARM3-____-BEDFORD\n3  BEDFORD  ROBOARM4       None     None  ROBOARM4-____-BEDFORD\n4  BEDFORD  ROBOARM5       None     None  ROBOARM5-____-BEDFORD\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.275 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Validating asset device mappings...\n2023-07-24T13:03:03.276 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Generated asset_device_mappings={'ROBOARM1-____-BEDFORD': [], 'ROBOARM2-____-BEDFORD': [], 'ROBOARM3-____-BEDFORD': [], 'ROBOARM4-____-BEDFORD': [], 'ROBOARM5-____-BEDFORD': [], 'ROBOARM6-____-BEDFORD': [], 'ROBOARM7-____-BEDFORD': [], 'ROBOARM8-____-BEDFORD': [], 'ROBOARM9-____-BEDFORD': []}\n2023-07-24T13:03:03.277 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Generated device type to features: features_meta={'': {'statusdate', 'installdate', 'status'}}\n2023-07-24T13:03:03.277 DEBUG::pmlib.loader.AssetLoader._validate_mappings: Generated mappings_meta=set()\n2023-07-24T13:03:03.278 DEBUG::pmlib.loader.AssetLoader._set_asset_device_mappings: Set asset device mappings: input_asset_device_mappings={'ROBOARM1-____-BEDFORD': [], 'ROBOARM2-____-BEDFORD': [], 'ROBOARM3-____-BEDFORD': [], 'ROBOARM4-____-BEDFORD': [], 'ROBOARM5-____-BEDFORD': [], 'ROBOARM6-____-BEDFORD': [], 'ROBOARM7-____-BEDFORD': [], 'ROBOARM8-____-BEDFORD': [], 'ROBOARM9-____-BEDFORD': []}, asset_device_mappings={'ROBOARM1-____-BEDFORD': [], 'ROBOARM2-____-BEDFORD': [], 'ROBOARM3-____-BEDFORD': [], 'ROBOARM4-____-BEDFORD': [], 'ROBOARM5-____-BEDFORD': [], 'ROBOARM6-____-BEDFORD': [], 'ROBOARM7-____-BEDFORD': [], 'ROBOARM8-____-BEDFORD': [], 'ROBOARM9-____-BEDFORD': []}, entity_type_meta={'': ['statusdate', 'installdate', 'status']}\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T13:03:03.295 DEBUG::pmlib.loader.AssetLoader.execute: Converted asset device mappings to DataFrame: df_mappings=\n=========== START DATAFRAME LOG ===========\nshape=(9, 3), \nindex={0: 'int64'}, \ncolumns={'asset_id': 'O', 'entity_type': 'O', 'id': 'O'}, \nhead(5)=\n                asset_id entity_type   id\n0  ROBOARM1-____-BEDFORD         NaN  NaN\n1  ROBOARM2-____-BEDFORD         NaN  NaN\n2  ROBOARM3-____-BEDFORD         NaN  NaN\n3  ROBOARM4-____-BEDFORD         NaN  NaN\n4  ROBOARM5-____-BEDFORD         NaN  NaN\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:03.296 DEBUG::pmlib.loader.AssetLoader.execute: Iterating over entity types to prep DataFrames for merging...\n2023-07-24T13:03:03.297 DEBUG::pmlib.loader.AssetLoader.execute: Current iteration: entity_type=, data_items=['statusdate', 'installdate', 'status'], is_asset_data=True\n2023-07-24T13:03:03.297 DEBUG::pmlib.loader.AssetLoader.execute: Separating asset time series data from non time series data...\n2023-07-24T13:03:03.298 DEBUG::pmlib.loader.AssetLoader.execute: data_items=['statusdate', 'installdate', 'status']\n2023-07-24T13:03:03.298 DEBUG::pmlib.loader.AssetLoader.execute: Updated timeseries data items: ts_data_items=set()\n2023-07-24T13:03:03.298 DEBUG::pmlib.loader.AssetLoader.execute: Final time series data items: ts_data_items=set()\n2023-07-24T13:03:03.299 DEBUG::pmlib.loader.AssetLoader.execute: Final non time series data items: non_ts_data_items={'statusdate', 'installdate', 'status'}\n2023-07-24T13:03:03.299 DEBUG::pmlib.util.api_request: Making API Request: method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/devicemapping?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json=None, session=None, kwargs={}\n2023-07-24T13:03:03.635 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=get, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/assetgroup/1002/devicemapping?instanceId=masdev\n2023-07-24T13:03:03.637 DEBUG::pmlib.api.get_maximo_asset_device_mappings: Call get_maximo_asset_device_mappings resp: {\"1002\":[{\"devices\":[],\"assetNum\":\"ROBOARM1\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM2\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM3\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM4\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM5\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM6\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM7\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM8\",\"siteId\":\"BEDFORD\"},{\"devices\":[],\"assetNum\":\"ROBOARM9\",\"siteId\":\"BEDFORD\"}]}\n2023-07-24T13:03:03.638 DEBUG::pmlib.util.api_request: Making API Request: method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/pmiboard/assetmeta?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json={'assets': [{'assetNum': 'ROBOARM1', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM2', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM3', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM4', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM5', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM6', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM7', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM8', 'siteId': 'BEDFORD'}, {'assetNum': 'ROBOARM9', 'siteId': 'BEDFORD'}], 'attributes': ['statusdate', 'installdate', 'status']}, session=None, kwargs={}\n2023-07-24T13:03:04.906 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/pmiboard/assetmeta?instanceId=masdev\n2023-07-24T13:03:04.914 DEBUG::pmlib.loader.AssetLoader.execute: df_loaded_asset_dimension=\n=========== START DATAFRAME LOG ===========\nshape=(9, 4), \nindex={0: 'int64'}, \ncolumns={'asset_id': 'O', 'statusdate': datetime64[ns, UTC], 'installdate': '<M8[ns]', 'status': 'O'}, \nhead(5)=\n                asset_id                statusdate installdate  status\n0  ROBOARM1-____-BEDFORD 2023-06-26 05:07:23+00:00  2016-05-05  ACTIVE\n1  ROBOARM2-____-BEDFORD 2023-07-17 07:58:02+00:00  2016-05-05  ACTIVE\n2  ROBOARM3-____-BEDFORD 2023-07-17 08:13:08+00:00  2016-05-05  ACTIVE\n3  ROBOARM4-____-BEDFORD 2023-07-17 08:13:23+00:00  2016-05-07  ACTIVE\n4  ROBOARM5-____-BEDFORD 2023-07-24 13:02:24+00:00  2016-05-10  BROKEN\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.915 DEBUG::pmlib.loader.AssetLoader.execute: Finished iterating over entity types. Retrieved 0 asset DataFrames and 0 sensor DataFrames\n2023-07-24T13:03:04.916 WARNING::pmlib.loader.AssetLoader.execute: No data found\n2023-07-24T13:03:04.917 DEBUG::pmlib.loader.AssetLoader.execute: Merging new DF with asset_dimension DF...\n2023-07-24T13:03:04.922 DEBUG::pmlib.loader.AssetLoader.execute: Sorted DF by time and dropped columns. df=\n=========== START DATAFRAME LOG ===========\nshape=(9, 3), \nindex={'asset_id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'statusdate': datetime64[ns, UTC], 'installdate': '<M8[ns]', 'status': 'O'}, \n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.926 DEBUG::pmlib.loader.AssetLoader.execute: Reordered columns according to config: df=\n=========== START DATAFRAME LOG ===========\nshape=(9, 3), \nindex={'asset_id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(5)=\n                                                       installdate  \\\nasset_id              evt_timestamp                                  \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  2016-05-05   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  2016-05-05   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  2016-05-05   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  2016-05-07   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  2016-05-10   \n\n                                                                      statusdate  \\\nasset_id              evt_timestamp                                                \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00 2023-06-26 05:07:23+00:00   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00 2023-07-17 07:58:02+00:00   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00 2023-07-17 08:13:08+00:00   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00 2023-07-17 08:13:23+00:00   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00 2023-07-24 13:02:24+00:00   \n\n                                                        status  \nasset_id              evt_timestamp                             \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  ACTIVE  \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  ACTIVE  \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  ACTIVE  \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  ACTIVE  \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  BROKEN  \n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.930 DEBUG::pmlib.loader.AssetLoader.execute: Finished executing AssetLoader. Final DF: \n=========== START DATAFRAME LOG ===========\nshape=(9, 3), \nindex={'id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(5)=\n                                                       installdate  \\\nid                    evt_timestamp                                  \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  2016-05-05   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  2016-05-05   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  2016-05-05   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  2016-05-07   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  2016-05-10   \n\n                                                                      statusdate  \\\nid                    evt_timestamp                                                \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00 2023-06-26 05:07:23+00:00   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00 2023-07-17 07:58:02+00:00   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00 2023-07-17 08:13:08+00:00   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00 2023-07-17 08:13:23+00:00   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00 2023-07-24 13:02:24+00:00   \n\n                                                        status  \nid                    evt_timestamp                             \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  ACTIVE  \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  ACTIVE  \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  ACTIVE  \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  ACTIVE  \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  BROKEN  \n=========== END DATAFRAME LOG ===========\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T13:03:04.936 DEBUG::pmlib.degradation_curve.DegradationCurveInputDataFilter.execute: df_input=\n=========== START DATAFRAME LOG ===========\nshape=(9, 3), \nindex={'id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(5)=\n                                                       installdate  \\\nid                    evt_timestamp                                  \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  2016-05-05   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  2016-05-05   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  2016-05-05   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  2016-05-07   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  2016-05-10   \n\n                                                                      statusdate  \\\nid                    evt_timestamp                                                \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00 2023-06-26 05:07:23+00:00   \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00 2023-07-17 07:58:02+00:00   \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00 2023-07-17 08:13:08+00:00   \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00 2023-07-17 08:13:23+00:00   \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00 2023-07-24 13:02:24+00:00   \n\n                                                        status  \nid                    evt_timestamp                             \nROBOARM1-____-BEDFORD 2023-07-24 12:55:04.917807+00:00  ACTIVE  \nROBOARM2-____-BEDFORD 2023-07-24 12:56:04.917807+00:00  ACTIVE  \nROBOARM3-____-BEDFORD 2023-07-24 12:57:04.917807+00:00  ACTIVE  \nROBOARM4-____-BEDFORD 2023-07-24 12:58:04.917807+00:00  ACTIVE  \nROBOARM5-____-BEDFORD 2023-07-24 12:59:04.917807+00:00  BROKEN  \n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.940 DEBUG::pmlib.degradation_curve.DegradationCurveInputDataFilter.execute: df_final=\n=========== START DATAFRAME LOG ===========\nshape=(4, 3), \nindex={'id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(10)=\n                                                       installdate  \\\nid                    evt_timestamp                                  \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00  2012-07-10   \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00  2015-07-21   \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00  2011-07-12   \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00  2008-07-22   \n\n                                                                      statusdate  \\\nid                    evt_timestamp                                                \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00 2023-07-24 12:57:58+00:00   \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00 2023-07-24 12:58:06+00:00   \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00 2023-07-24 12:58:59+00:00   \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00 2023-07-24 12:59:44+00:00   \n\n                                                                status  \nid                    evt_timestamp                                     \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00  DECOMMISSIONED  \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00  DECOMMISSIONED  \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00  DECOMMISSIONED  \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00  DECOMMISSIONED  \n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.945 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.execute: Running estimator on input DataFrame: df=\n=========== START DATAFRAME LOG ===========\nshape=(4, 3), \nindex={'id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(5)=\n                                                       installdate  \\\nid                    evt_timestamp                                  \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00  2012-07-10   \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00  2015-07-21   \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00  2011-07-12   \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00  2008-07-22   \n\n                                                                      statusdate  \\\nid                    evt_timestamp                                                \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00 2023-07-24 12:57:58+00:00   \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00 2023-07-24 12:58:06+00:00   \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00 2023-07-24 12:58:59+00:00   \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00 2023-07-24 12:59:44+00:00   \n\n                                                                status  \nid                    evt_timestamp                                     \nROBOARM6-____-BEDFORD 2023-07-24 13:00:04.917807+00:00  DECOMMISSIONED  \nROBOARM7-____-BEDFORD 2023-07-24 13:01:04.917807+00:00  DECOMMISSIONED  \nROBOARM8-____-BEDFORD 2023-07-24 13:02:04.917807+00:00  DECOMMISSIONED  \nROBOARM9-____-BEDFORD 2023-07-24 13:03:04.917807+00:00  DECOMMISSIONED  \n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.954 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.execute: Training date range: training_date_range_df_result=\n=========== START DATAFRAME LOG ===========\nshape=(2, 1), \nindex={0: 'int64'}, \ncolumns={'evt_timestamp': datetime64[ns, UTC]}, \ndf=\n                     evt_timestamp\n0 2023-07-24 13:00:04.917807+00:00\n1 2023-07-24 13:03:04.917807+00:00\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.957 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.execute: Dataframe to train: df=\n=========== START DATAFRAME LOG ===========\nshape=(4, 3), \nindex={0: 'int64'}, \ncolumns={'installdate': '<M8[ns]', 'statusdate': datetime64[ns, UTC], 'status': 'O'}, \nhead(5)=\n  installdate                statusdate          status\n0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED\n1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED\n2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED\n3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:04.959 INFO::pmlib.degradation_curve.DegradationCurveEstimator.execute: Iterating over models to train...\n2023-07-24T13:03:04.959 INFO::pmlib.degradation_curve.DegradationCurveEstimator.execute: Beginning model training for model: None\ndf_input:   installdate                statusdate          status\n0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED\n1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED\n2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED\n3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED\ndf.shape=(4, 3)\ndf_input_filter:   installdate                statusdate          status\n0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED\n1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED\n2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED\n3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED\ndf_curve_training_data.shape=(4, 4)\ndf_curve_training_data=\n   index installdate                statusdate          status\n0      0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED\n1      1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED\n2      2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED\n3      3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED\ninitial mean_or_scale=None\ninitial stddev_or_shape=None\ndf_curve_training_data=   index installdate                statusdate          status\n0      0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED\n1      1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED\n2      2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED\n3      3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED\ncalculate the scale value and shape value for normal distribution...\ndate_service=0    12.0\n1     9.0\n2    13.0\n3    16.0\ndtype: float64\nsnapshot_year=2021\ndf_curve_training_data_pre_processing=\n   index installdate                statusdate          status  retired_flag  \\\n0      0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED             1   \n1      1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED             1   \n2      2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED             1   \n3      3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED             1   \n\n   date_service  \n0          12.0  \n1           9.0  \n2          13.0  \n3          16.0  \n(4, 6)\ndf_exposed_table=\n    age  retired_number  exposed_number\n0  16.0               1               1\n1  13.0               1               2\n2  12.0               1               3\n3   9.0               1               4\nmax_age = 16.0\n------------ 0\nNumber of exposed assets = number of retired assets in max_age, meaning all the asset observed failed at max_age\ndf_cfp_input=\n    age  retired_number  exposed_number\n1  13.0               1               2\n2  12.0               1               3\n3   9.0               1               4\ndf_cfp_add_1st dataframe=\n    age  retired_number  exposed_number  pre_cumulative_probability\n0  13.0             1.0             2.0                    0.500000\n1  12.0             1.0             3.0                    0.333333\n2   9.0             1.0             4.0                    0.250000\n3   8.0            -1.0            -1.0                    0.001000\nSeries([], Name: retired_number, dtype: float64)\nTony2\ndf_cfp dataframe=\n    age  retired_number  exposed_number  pre_cumulative_probability\n0  16.0            -1.0            -1.0                    0.000000\n1  13.0             1.0             2.0                    0.500000\n2  12.0             1.0             3.0                    0.333333\n3   9.0             1.0             4.0                    0.250000\n4   8.0            -1.0            -1.0                    0.001000\ndf_cfp_cumsum=\n    age  retired_number  exposed_number  pre_cumulative_probability  \\\n4   8.0            -1.0            -1.0                    0.001000   \n3   9.0             1.0             4.0                    0.250000   \n2  12.0             1.0             3.0                    0.333333   \n1  13.0             1.0             2.0                    0.500000   \n0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  \n4                0.001000  \n3                0.251000  \n2                0.584333  \n1                1.084333  \n0                1.084333  \ndf_cfp_cumsum=\n    age  retired_number  exposed_number  pre_cumulative_probability  \\\n4   8.0            -1.0            -1.0                    0.001000   \n3   9.0             1.0             4.0                    0.250000   \n2  12.0             1.0             3.0                    0.333333   \n1  13.0             1.0             2.0                    0.500000   \n0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  \n4                0.001000  \n3                0.251000  \n2                0.584333  \n1                1.084333  \n0                1.084333  \nToo many decomissioned assets. Switch to regular mean and std.\nmean_or_scale_NORMAL = 12.5\nstddev_or_shape_NORMAL = 2.886751345948129\ndf_cfp_tony=\n    age  retired_number  exposed_number  pre_cumulative_probability  \\\n4   8.0            -1.0            -1.0                    0.001000   \n3   9.0             1.0             4.0                    0.250000   \n2  12.0             1.0             3.0                    0.333333   \n1  13.0             1.0             2.0                    0.500000   \n0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  \n4                0.059516  \n3                0.112673  \n2                0.431245  \n1                0.568755  \n0                0.887327  \ndf_cfp_tony=\n    age  retired_number  exposed_number  pre_cumulative_probability  \\\n4   8.0            -1.0            -1.0                    0.001000   \n3   9.0             1.0             4.0                    0.250000   \n2  12.0             1.0             3.0                    0.333333   \n1  13.0             1.0             2.0                    0.500000   \n0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  \n4                0.059516  \n3                0.112673  \n2                0.431245  \n1                0.568755  \n0                0.887327  \nWEIBULL_input_df_cfp=\n    age  retired_number  exposed_number  pre_cumulative_probability  \\\n4   8.0            -1.0            -1.0                    0.001000   \n3   9.0             1.0             4.0                    0.250000   \n2  12.0             1.0             3.0                    0.333333   \n1  13.0             1.0             2.0                    0.500000   \n0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  \n4                0.059516  \n3                0.112673  \n2                0.431245  \n1                0.568755  \n0                0.887327  \ndf_cfp_survival=\n   index   age  retired_number  exposed_number  pre_cumulative_probability  \\\n0      4   8.0            -1.0            -1.0                    0.001000   \n1      3   9.0             1.0             4.0                    0.250000   \n2      2  12.0             1.0             3.0                    0.333333   \n3      1  13.0             1.0             2.0                    0.500000   \n4      0  16.0            -1.0            -1.0                    0.000000   \n\n   cumulative_probability  survival_probablity  \n0                0.059516             1.000000  \n1                0.112673             0.887327  \n2                0.431245             0.568755  \n3                0.568755             0.431245  \n4                0.887327             0.112673  \nage_array=[8.0, 9.0, 12.0, 13.0, 16.0]\nSP_array=[1.0, 0.8873271531491667, 0.5687548849320392, 0.4312451150679608, 0.11267284685083334]\nalpha=12.5\nbeta=2.886751345948129\nthe init performance objective function value is: 0.3515403297697966\nTony alpha is: 14\nTony beta is: 6\nTony new obj_function value is: 0.07377401960697343 alpha=14 beta=6\nin the while loop iteration=0\nthe new performance objective function value is: 0.07376250944303045 alpha=13.999916942927346 beta=5.9999320589480964\nin the while loop iteration=100\nthe new performance objective function value is: 0.0726875846954918 alpha=13.992221490647916 beta=5.9929903221513685\nin the while loop iteration=200\nthe new performance objective function value is: 0.07172840346284455 alpha=13.985578747926375 beta=5.985797480831546\nin the while loop iteration=300\nthe new performance objective function value is: 0.07084654629914969 alpha=13.979787883544558 beta=5.978407203318342\nin the while loop iteration=400\nthe new performance objective function value is: 0.07001688075630132 alpha=13.974684808179811 beta=5.970863811709022\nin the while loop iteration=500\nthe new performance objective function value is: 0.06922305910067547 alpha=13.970136160547824 beta=5.963203652914184\nin the while loop iteration=600\nthe new performance objective function value is: 0.06845449404986473 alpha=13.966034001864724 beta=5.955456371687937\nin the while loop iteration=700\nthe new performance objective function value is: 0.06770435147493822 alpha=13.962291251551793 beta=5.947646045253398\nin the while loop iteration=800\nthe new performance objective function value is: 0.06696823037847247 alpha=13.958837832188067 beta=5.939792166536844\nin the while loop iteration=900\nthe new performance objective function value is: 0.06624330102721626 alpha=13.955617457840853 beta=5.931910479247802\nin the while loop iteration=1000\nthe new performance objective function value is: 0.06552774531912849 alpha=13.952584985961106 beta=5.924013676734399\nin the while loop iteration=1100\nthe new performance objective function value is: 0.06482039493335413 alpha=13.94970425109691 beta=5.9161119804222295\nin the while loop iteration=1200\nthe new performance objective function value is: 0.06412049811676095 alpha=13.946946303409916 beta=5.90821361461421\nin the while loop iteration=1300\nthe new performance objective function value is: 0.06342756974343083 alpha=13.944287982949453 beta=5.900325193760212\nin the while loop iteration=1400\nthe new performance objective function value is: 0.06274129508962953 alpha=13.941710769753273 beta=5.89245203681047\nin the while loop iteration=1500\nthe new performance objective function value is: 0.06206146816563567 alpha=13.939199858903903 beta=5.884598421442847\nin the while loop iteration=1600\nthe new performance objective function value is: 0.06138795223493107 alpha=13.936743418043795 beta=5.876767789088443\nin the while loop iteration=1700\nthe new performance objective function value is: 0.060720654558126176 alpha=13.934331992261109 beta=5.868962909927647\nin the while loop iteration=1800\nthe new performance objective function value is: 0.06005951024701276 alpha=13.93195802762658 beta=5.86118601546168\nin the while loop iteration=1900\nthe new performance objective function value is: 0.05940447194876747 alpha=13.929615490028343 beta=5.8534389049074536\nin the while loop iteration=2000\nthe new performance objective function value is: 0.0587555032592493 alpha=13.92729956040914 beta=5.84572303051308\nin the while loop iteration=2100\nthe new performance objective function value is: 0.058112574520583625 alpha=13.9250063911747 beta=5.838039565931018\nin the while loop iteration=2200\nthe new performance objective function value is: 0.05747566014275379 alpha=13.922732911530732 beta=5.830389460993249\nin the while loop iteration=2300\nthe new performance objective function value is: 0.05684473689903283 alpha=13.920476671929338 beta=5.822773485583831\nin the while loop iteration=2400\nthe new performance objective function value is: 0.056219782843524274 alpha=13.91823571976196 beta=5.815192264776482\nin the while loop iteration=2500\nthe new performance objective function value is: 0.055600776625954806 alpha=13.91600850001004 beta=5.8076463069772295\nin the while loop iteration=2600\nthe new performance objective function value is: 0.054987697060007855 alpha=13.91379377582764 beta=5.800136026467321\nin the while loop iteration=2700\nthe new performance objective function value is: 0.05438052285334352 alpha=13.911590565042077 beta=5.79266176146395\nin the while loop iteration=2800\nthe new performance objective function value is: 0.05377923244064006 alpha=13.90939808936795 beta=5.78522378859365\nin the while loop iteration=2900\nthe new performance objective function value is: 0.05318380388217432 alpha=13.907215733776635 beta=5.77782233449424\nin the while loop iteration=3000\nthe new performance objective function value is: 0.05259421480401433 alpha=13.905043013979487 beta=5.77045758511811\nin the while loop iteration=3100\nthe new performance objective function value is: 0.05201044236459023 alpha=13.902879550395342 beta=5.7631296931952125\nin the while loop iteration=3200\nthe new performance objective function value is: 0.051432463237901675 alpha=13.900725047301497 beta=5.7558387842221155\nin the while loop iteration=3300\nthe new performance objective function value is: 0.050860253607198556 alpha=13.89857927612954 beta=5.748584961270496\nin the while loop iteration=3400\nthe new performance objective function value is: 0.05029378916520596 alpha=13.896442062076808 beta=5.741368308849643\nin the while loop iteration=3500\nthe new performance objective function value is: 0.04973304511841546 alpha=13.894313273370969 beta=5.734188896010788\nin the while loop iteration=3600\nthe new performance objective function value is: 0.04917799619387484 alpha=13.892192812658472 beta=5.7270467788435155\n", "name": "stdout"}, {"output_type": "stream", "text": "in the while loop iteration=3700\nthe new performance objective function value is: 0.04862861664750307 alpha=13.890080610093793 beta=5.719942002484718\nin the while loop iteration=3800\nthe new performance objective function value is: 0.048084880273308477 alpha=13.88797661779122 beta=5.71287460273636\nin the while loop iteration=3900\nthe new performance objective function value is: 0.04754676041314117 alpha=13.88588080536856 beta=5.705844607369419\nin the while loop iteration=4000\nthe new performance objective function value is: 0.047014229966748596 alpha=13.883793156366544 beta=5.6988520371758415\nin the while loop iteration=4100\nthe new performance objective function value is: 0.04648726140198916 alpha=13.881713665370315 beta=5.691896906818195\nin the while loop iteration=4200\nthe new performance objective function value is: 0.04596582676512886 alpha=13.87964233569461 beta=5.684979225516756\nin the while loop iteration=4300\nthe new performance objective function value is: 0.04544989769116988 alpha=13.877579177521218 beta=5.678098997606097\nin the while loop iteration=4400\nthe new performance objective function value is: 0.04493944541418853 alpha=13.875524206399769 beta=5.671256222986695\nin the while loop iteration=4500\nthe new performance objective function value is: 0.04443444077766368 alpha=13.873477442040546 beta=5.664450897492234\nin the while loop iteration=4600\nthe new performance objective function value is: 0.04393485424479314 alpha=13.87143890734178 beta=5.657683013189087\nin the while loop iteration=4700\nthe new performance objective function value is: 0.043440655908795485 alpha=13.86940862760581 beta=5.650952558621303\nin the while loop iteration=4800\nthe new performance objective function value is: 0.04295181550319133 alpha=13.867386629906967 beta=5.644259519011768\nin the while loop iteration=4900\nthe new performance objective function value is: 0.042468302412072875 alpha=13.865372942581724 beta=5.63760387642814\nin the while loop iteration=5000\nthe new performance objective function value is: 0.041990085680347344 alpha=13.863367594817209 beta=5.630985609920425\nin the while loop iteration=5100\nthe new performance objective function value is: 0.041517134023970885 alpha=13.861370616319066 beta=5.624404695635835\nin the while loop iteration=5200\nthe new performance objective function value is: 0.04104941584015593 alpha=13.859382037043227 beta=5.617861106915311\nin the while loop iteration=5300\nthe new performance objective function value is: 0.040586899217563345 alpha=13.857401886979261 beta=5.611354814375405\nin the while loop iteration=5400\nthe new performance objective function value is: 0.04012955194646926 alpha=13.855430195975302 beta=5.6048857859783485\nin the while loop iteration=5500\nthe new performance objective function value is: 0.03967734152890593 alpha=13.853466993596626 beta=5.598453987092673\nin the while loop iteration=5600\nthe new performance objective function value is: 0.03923023518878098 alpha=13.851512309011387 beta=5.592059380546302\nin the while loop iteration=5700\nthe new performance objective function value is: 0.038788199881959376 alpha=13.849566170898301 beta=5.585701926673556\nin the while loop iteration=5800\nthe new performance objective function value is: 0.03835120230631767 alpha=13.847628607372128 beta=5.57938158335736\nin the while loop iteration=5900\nthe new performance objective function value is: 0.03791920891176006 alpha=13.845699645923506 beta=5.573098306067633\nin the while loop iteration=6000\nthe new performance objective function value is: 0.037492185910194355 alpha=13.843779313370579 beta=5.566852047896583\nin the while loop iteration=6100\nthe new performance objective function value is: 0.03707009928546615 alpha=13.84186763581999 beta=5.560642759591651\nin the while loop iteration=6200\nthe new performance objective function value is: 0.03665291480324575 alpha=13.839964638635633 beta=5.5544703895865535\nin the while loop iteration=6300\nthe new performance objective function value is: 0.03624059802086448 alpha=13.838070346413708 beta=5.548334884030838\nin the while loop iteration=6400\nthe new performance objective function value is: 0.03583311429709786 alpha=13.83618478296282 beta=5.542236186818315\nin the while loop iteration=6500\nthe new performance objective function value is: 0.03543042880189329 alpha=13.834307971288357 beta=5.536174239614613\nin the while loop iteration=6600\nthe new performance objective function value is: 0.035032506526034506 alpha=13.832439933580215 beta=5.530148981884087\nin the while loop iteration=6700\nthe new performance objective function value is: 0.03463931229074378 alpha=13.830580691203373 beta=5.524160350916234\nin the while loop iteration=6800\nthe new performance objective function value is: 0.034250810757215956 alpha=13.828730264690781 beta=5.518208281851756\nin the while loop iteration=6900\nthe new performance objective function value is: 0.033866966436082786 alpha=13.826888673738146 beta=5.512292707708402\nin the while loop iteration=7000\nthe new performance objective function value is: 0.03348774369680186 alpha=13.825055937200327 beta=5.506413559406655\nin the while loop iteration=7100\nthe new performance objective function value is: 0.03311310677696953 alpha=13.823232073089041 beta=5.500570765795325\nin the while loop iteration=7200\nthe new performance objective function value is: 0.032743019791553404 alpha=13.82141709857169 beta=5.4947642536771255\nin the while loop iteration=7300\nthe new performance objective function value is: 0.0323774467420402 alpha=13.819611029971083 beta=5.4889939478342615\nin the while loop iteration=7400\nthe new performance objective function value is: 0.03201635152550052 alpha=13.817813882766005 beta=5.483259771054058\nin the while loop iteration=7500\nthe new performance objective function value is: 0.03165969794356104 alpha=13.816025671592437 beta=5.47756164415467\nin the while loop iteration=7600\nthe new performance objective function value is: 0.0313074497112868 alpha=13.814246410245325 beta=5.47189948601084\nin the while loop iteration=7700\nthe new performance objective function value is: 0.030959570465969255 alpha=13.812476111680912 beta=5.466273213579818\nin the while loop iteration=7800\nthe new performance objective function value is: 0.03061602377581714 alpha=13.810714788019476 beta=5.460682741927337\nin the while loop iteration=7900\nthe new performance objective function value is: 0.03027677314854586 alpha=13.808962450548435 beta=5.455127984253695\nin the while loop iteration=8000\nthe new performance objective function value is: 0.029941782039868244 alpha=13.80721910972582 beta=5.44960885192\nin the while loop iteration=8100\nthe new performance objective function value is: 0.02961101386187906 alpha=13.805484775184102 beta=5.444125254474481\nin the while loop iteration=8200\nthe new performance objective function value is: 0.029284431991334733 alpha=13.803759455734188 beta=5.438677099678941\nin the while loop iteration=8300\nthe new performance objective function value is: 0.028961999777822194 alpha=13.802043159369797 beta=5.433264293535279\nin the while loop iteration=8400\nthe new performance objective function value is: 0.02864368055181973 alpha=13.800335893271946 beta=5.427886740312154\nin the while loop iteration=8500\nthe new performance objective function value is: 0.028329437632645754 alpha=13.798637663813762 beta=5.422544342571744\nin the while loop iteration=8600\nthe new performance objective function value is: 0.02801923433629209 alpha=13.796948476565433 beta=5.417237001196561\nin the while loop iteration=8700\nthe new performance objective function value is: 0.027713033983142128 alpha=13.79526833629935 beta=5.4119646154163865\nin the while loop iteration=8800\nthe new performance objective function value is: 0.027410799905571808 alpha=13.793597246995441 beta=5.40672708283527\nin the while loop iteration=8900\nthe new performance objective function value is: 0.027112495455432723 alpha=13.791935211846674 beta=5.401524299458595\nin the while loop iteration=9000\nthe new performance objective function value is: 0.02681808401141361 alpha=13.790282233264726 beta=5.396356159720215\nin the while loop iteration=9100\nthe new performance objective function value is: 0.026527528986281763 alpha=13.788638312885753 beta=5.3912225565096366\nin the while loop iteration=9200\nthe new performance objective function value is: 0.02624079383400074 alpha=13.787003451576378 beta=5.3861233811992495\nin the while loop iteration=9300\nthe new performance objective function value is: 0.0259578420567251 alpha=13.785377649439777 beta=5.38105852367159\nin the while loop iteration=9400\nthe new performance objective function value is: 0.025678637211670713 alpha=13.783760905821884 beta=5.376027872346642\nin the while loop iteration=9500\nthe new performance objective function value is: 0.025403142917857814 alpha=13.78215321931773 beta=5.3710313142091595\nin the while loop iteration=9600\nthe new performance objective function value is: 0.025131322862729837 alpha=13.780554587777972 beta=5.366068734835986\nin the while loop iteration=9700\nthe new performance objective function value is: 0.024863140808644418 alpha=13.77896500831543 beta=5.361140018423407\nin the while loop iteration=9800\nthe new performance objective function value is: 0.024598560599233977 alpha=13.777384477311784 beta=5.3562450478144505\nin the while loop iteration=9900\nthe new performance objective function value is: 0.02433754616564248 alpha=13.775812990424404 beta=5.351383704526237\nthe optimal alpha is 13.77426612234661\nthe optimal beta is 5.346603981668854\nthe optimal performance objective function value is: 0.024082619024329233\nmean_or_scale_WEIBULL=13.77426612234661\nstddev_or_shape_WEIBULL=5.346603981668854\ncalculate done\ngenerate final degradation curve\nfinal_degradation_curve=\n{0: 0.0, 1: 8.125532086067366e-05, 2: 0.0033062293736785264, 3: 0.02889133712595804, 4: 0.13444239213655784, 5: 0.4425934045437341, 6: 1.1688746273932904, 7: 2.645138144337955, 8: 5.3270131664565294, 9: 9.76532215177295, 10: 16.513995013843218, 11: 25.951202687612273, 12: 38.0236386926448, 13: 51.99903692075603, 14: 66.40520140308718, 15: 79.34919385608559, 16: 89.21952064840792, 17: 95.40486866750774, 18: 98.47192538568261, 19: 99.62374514117917, 20: 99.93536659045472, 21: 99.99275864551413, 22: 99.9995094515793, 23: 99.9999815384171, 24: 99.99999964870693, 25: 99.99999999695504, 26: 99.99999999998929, 27: 99.99999999999999, 28: 100.0, 29: 100.0, 30: 100.0, 31: 100.0, 32: 100.0, 33: 100.0, 34: 100.0, 35: 100.0, 36: 100.0, 37: 100.0, 38: 100.0, 39: 100.0, 40: 100.0, 41: 100.0, 42: 100.0, 43: 100.0, 44: 100.0, 45: 100.0, 46: 100.0, 47: 100.0, 48: 100.0, 49: 100.0, 50: 100.0, 51: 100.0, 52: 100.0, 53: 100.0, 54: 100.0, 55: 100.0, 56: 100.0, 57: 100.0, 58: 100.0, 59: 100.0, 60: 100.0, 61: 100.0, 62: 100.0, 63: 100.0, 64: 100.0, 65: 100.0, 66: 100.0, 67: 100.0, 68: 100.0, 69: 100.0, 70: 100.0, 71: 100.0, 72: 100.0, 73: 100.0, 74: 100.0, 75: 100.0, 76: 100.0, 77: 100.0, 78: 100.0, 79: 100.0, 80: 100.0, 81: 100.0, 82: 100.0, 83: 100.0, 84: 100.0, 85: 100.0, 86: 100.0, 87: 100.0, 88: 100.0, 89: 100.0, 90: 100.0, 91: 100.0, 92: 100.0, 93: 100.0, 94: 100.0, 95: 100.0, 96: 100.0, 97: 100.0, 98: 100.0, 99: 100.0, 100: 100.0}\ndfinal_degradation_curve=\n   index installdate                statusdate          status  retired_flag  \\\n0      0  2012-07-10 2023-07-24 12:57:58+00:00  DECOMMISSIONED             1   \n1      1  2015-07-21 2023-07-24 12:58:06+00:00  DECOMMISSIONED             1   \n2      2  2011-07-12 2023-07-24 12:58:59+00:00  DECOMMISSIONED             1   \n3      3  2008-07-22 2023-07-24 12:59:44+00:00  DECOMMISSIONED             1   \n\n   date_service  \n0          12.0  \n1           9.0  \n2          13.0  \n3          16.0  \n2023-07-24T13:03:05.287 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.get_model_extra: extras=[('apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json', '{\"final_degradation_curve\": {\"0\": 0.0, \"1\": 8.125532086067366e-05, \"2\": 0.0033062293736785264, \"3\": 0.02889133712595804, \"4\": 0.13444239213655784, \"5\": 0.4425934045437341, \"6\": 1.1688746273932904, \"7\": 2.645138144337955, \"8\": 5.3270131664565294, \"9\": 9.76532215177295, \"10\": 16.513995013843218, \"11\": 25.951202687612273, \"12\": 38.0236386926448, \"13\": 51.99903692075603, \"14\": 66.40520140308718, \"15\": 79.34919385608559, \"16\": 89.21952064840792, \"17\": 95.40486866750774, \"18\": 98.47192538568261, \"19\": 99.62374514117917, \"20\": 99.93536659045472, \"21\": 99.99275864551413, \"22\": 99.9995094515793, \"23\": 99.9999815384171, \"24\": 99.99999964870693, \"25\": 99.99999999695504, \"26\": 99.99999999998929, \"27\": 99.99999999999999, \"28\": 100.0, \"29\": 100.0, \"30\": 100.0, \"31\": 100.0, \"32\": 100.0, \"33\": 100.0, \"34\": 100.0, \"35\": 100.0, \"36\": 100.0, \"37\": 100.0, \"38\": 100.0, \"39\": 100.0, \"40\": 100.0, \"41\": 100.0, \"42\": 100.0, \"43\": 100.0, \"44\": 100.0, \"45\": 100.0, \"46\": 100.0, \"47\": 100.0, \"48\": 100.0, \"49\": 100.0, \"50\": 100.0, \"51\": 100.0, \"52\": 100.0, \"53\": 100.0, \"54\": 100.0, \"55\": 100.0, \"56\": 100.0, \"57\": 100.0, \"58\": 100.0, \"59\": 100.0, \"60\": 100.0, \"61\": 100.0, \"62\": 100.0, \"63\": 100.0, \"64\": 100.0, \"65\": 100.0, \"66\": 100.0, \"67\": 100.0, \"68\": 100.0, \"69\": 100.0, \"70\": 100.0, \"71\": 100.0, \"72\": 100.0, \"73\": 100.0, \"74\": 100.0, \"75\": 100.0, \"76\": 100.0, \"77\": 100.0, \"78\": 100.0, \"79\": 100.0, \"80\": 100.0, \"81\": 100.0, \"82\": 100.0, \"83\": 100.0, \"84\": 100.0, \"85\": 100.0, \"86\": 100.0, \"87\": 100.0, \"88\": 100.0, \"89\": 100.0, \"90\": 100.0, \"91\": 100.0, \"92\": 100.0, \"93\": 100.0, \"94\": 100.0, \"95\": 100.0, \"96\": 100.0, \"97\": 100.0, \"98\": 100.0, \"99\": 100.0, \"100\": 100.0}}', False, False)]\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T13:03:05.289 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:05.291 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785\n2023-07-24T13:03:05.292 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:05.293 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json\n2023-07-24T13:03:05.298 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.execute: Final DF with predictions: \n=========== START DATAFRAME LOG ===========\nshape=(4, 0), \nindex={'id': 'O', 'evt_timestamp': datetime64[ns, UTC]}, \ncolumns={}, \ndf=Empty DataFrame\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:05.300 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Initializing ModelPipelineConfig Dict with the following parameters: features=[], features_for_training=['installdate', 'statusdate', 'status'], predictions=[], features_resampled={}, inputs=(), renamed_inputs=()\n2023-07-24T13:03:05.301 DEBUG::pmlib.pipeline._ModelPipelineConfig.__init__: Added kwargs to ModelPipelineConfig: {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:05.302 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_pipeline_config: Subclass's prepared_model_config: {'features': [], 'features_for_training': ['installdate', 'statusdate', 'status'], 'targets': ['installdate', 'statusdate', 'status'], 'predictions': [], 'features_resampled': {}, 'inputs': (), 'renamed_inputs': (), 'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}}\n2023-07-24T13:03:05.302 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._get_latest_prediction_timestamp: Retrieved prediction table name: None\n2023-07-24T13:03:05.303 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: new_training=True, training_timestamp=1690203785, model_timestampe={'DegradationCurveEstimator': '1690203785'}\n2023-07-24T13:03:05.307 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: Pipeline final DF=\n=========== START DATAFRAME LOG ===========\nshape=(0, 0), \nindex={'id': 'O', 'evt_timestamp': 'O'}, \ncolumns={}, \nmissing_value_count={}\ndf=Empty DataFrame\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:05.308 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.execute: Finished execution of End of Life Curve Asset Group Pipeline.\n", "name": "stdout"}]}, {"metadata": {"id": "2cbe1f52-9d93-4769-b988-1fd878a3d1a1"}, "cell_type": "markdown", "source": "After this method completes successfully, you have a trained model instance ready, and the prediction results are returned as a dataframe for verification."}, {"metadata": {"id": "7fc778e9-f367-41b1-bdbf-1c0dd93fe6b1"}, "cell_type": "markdown", "source": "<a id=\"register-trained-model-instance\"></a>\n## Register the trained model instance\n"}, {"metadata": {"id": "51e09689-71d7-44a3-bd0e-575dd9595a3c"}, "cell_type": "markdown", "source": "If the trained model instance looks good, you can register it to Maximo Predict:"}, {"metadata": {"id": "4b59babd-3d37-42a0-80bc-ec99ffbdf731", "scrolled": true}, "cell_type": "code", "source": "group.register()", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "2023-07-24T13:03:32.302 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Beginning registration of model to Maximo Predict...\n2023-07-24T13:03:32.303 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: target_pipeline_class=pmlib.degradation_curve.DegradationCurveAssetGroupPipeline\n2023-07-24T13:03:32.304 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Model Template ID: DegradationCurveAssetGroupPipeline\n2023-07-24T13:03:32.305 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: This class name: DegradationCurveAssetGroupPipeline\n2023-07-24T13:03:32.306 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Registering model template...\n2023-07-24T13:03:32.307 DEBUG::pmlib.util.api_request: Making API Request: method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/template?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json={'modelTemplateId': 'DegradationCurveAssetGroupPipeline', 'modelTemplateName': 'End of Life Curve', 'modelTemplateDesc': 'End of Life Curve', 'modelJson': {'name': 'DegradationCurveAssetGroupPipeline', 'description': 'DegradationCurveAssetGroupPipeline', 'moduleAndTargetName': 'pmlib.degradation_curve.DegradationCurveAssetGroupPipeline', 'url': 'https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/masdev/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/lib/download?filename=pmlib', 'category': 'TRANSFORMER', 'tags': [], 'output': [{'name': 'names', 'description': 'Provide a list of output names to be generated from the pipeline.', 'dataType': 'ARRAY', 'jsonSchema': {'minItems': 1, '$schema': 'http://json-schema.org/draft-07/schema#', 'type': 'array', 'items': {'type': 'string'}}, 'tags': []}], 'input': [{'name': 'asset_group_id', 'type': 'CONSTANT', 'required': True, 'dataType': 'LITERAL'}, {'name': 'model_pipeline', 'type': 'CONSTANT', 'required': True, 'dataType': 'JSON'}, {'name': 'fillna', 'type': 'CONSTANT', 'required': False, 'dataType': 'LITERAL', 'values': ['backfill', 'bfill', 'ffill', 'pad']}, {'name': 'fillna_exclude', 'type': 'CONSTANT', 'required': False, 'dataType': 'ARRAY', 'dataTypeForArray': ['LITERAL'], 'jsonSchema': {'minItems': 1, '$schema': 'http://json-schema.org/draft-07/schema#', 'type': 'array', 'items': {'type': 'string'}}}, {'name': 'dropna', 'type': 'CONSTANT', 'required': False, 'dataType': 'LITERAL', 'values': ['any', 'all']}, {'name': 'dropna_exclude', 'type': 'CONSTANT', 'required': False, 'dataType': 'ARRAY', 'dataTypeForArray': ['LITERAL'], 'jsonSchema': {'minItems': 1, '$schema': 'http://json-schema.org/draft-07/schema#', 'type': 'array', 'items': {'type': 'string'}}}, {'name': 'asset_device_mappings', 'type': 'CONSTANT', 'required': False, 'dataType': 'JSON'}, {'name': 'model_timestamp', 'type': 'CONSTANT', 'required': False, 'dataType': 'JSON'}, {'name': 'local_model', 'type': 'CONSTANT', 'required': False, 'dataType': 'BOOLEAN'}, {'name': 'incremental_summary', 'type': 'CONSTANT', 'required': False, 'dataType': 'BOOLEAN'}, {'name': 'apm_id', 'type': 'CONSTANT', 'required': False, 'dataType': 'LITERAL'}, {'name': 'apm_api_baseurl', 'type': 'CONSTANT', 'required': False, 'dataType': 'LITERAL'}, {'name': 'apm_api_baseurl', 'type': 'CONSTANT', 'required': False, 'dataType': 'LITERAL'}, {'name': 'target_pipeline_name', 'type': 'CONSTANT', 'required': True, 'dataType': 'LITERAL'}]}}, session=None, kwargs={}\n2023-07-24T13:03:33.668 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/template?instanceId=masdev\n2023-07-24T13:03:33.670 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Model registration response: <Response [200]>\n2023-07-24T13:03:34.534 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.get_model_extra: extras=[('apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json', '{\"final_degradation_curve\": {\"0\": 0.0, \"1\": 8.125532086067366e-05, \"2\": 0.0033062293736785264, \"3\": 0.02889133712595804, \"4\": 0.13444239213655784, \"5\": 0.4425934045437341, \"6\": 1.1688746273932904, \"7\": 2.645138144337955, \"8\": 5.3270131664565294, \"9\": 9.76532215177295, \"10\": 16.513995013843218, \"11\": 25.951202687612273, \"12\": 38.0236386926448, \"13\": 51.99903692075603, \"14\": 66.40520140308718, \"15\": 79.34919385608559, \"16\": 89.21952064840792, \"17\": 95.40486866750774, \"18\": 98.47192538568261, \"19\": 99.62374514117917, \"20\": 99.93536659045472, \"21\": 99.99275864551413, \"22\": 99.9995094515793, \"23\": 99.9999815384171, \"24\": 99.99999964870693, \"25\": 99.99999999695504, \"26\": 99.99999999998929, \"27\": 99.99999999999999, \"28\": 100.0, \"29\": 100.0, \"30\": 100.0, \"31\": 100.0, \"32\": 100.0, \"33\": 100.0, \"34\": 100.0, \"35\": 100.0, \"36\": 100.0, \"37\": 100.0, \"38\": 100.0, \"39\": 100.0, \"40\": 100.0, \"41\": 100.0, \"42\": 100.0, \"43\": 100.0, \"44\": 100.0, \"45\": 100.0, \"46\": 100.0, \"47\": 100.0, \"48\": 100.0, \"49\": 100.0, \"50\": 100.0, \"51\": 100.0, \"52\": 100.0, \"53\": 100.0, \"54\": 100.0, \"55\": 100.0, \"56\": 100.0, \"57\": 100.0, \"58\": 100.0, \"59\": 100.0, \"60\": 100.0, \"61\": 100.0, \"62\": 100.0, \"63\": 100.0, \"64\": 100.0, \"65\": 100.0, \"66\": 100.0, \"67\": 100.0, \"68\": 100.0, \"69\": 100.0, \"70\": 100.0, \"71\": 100.0, \"72\": 100.0, \"73\": 100.0, \"74\": 100.0, \"75\": 100.0, \"76\": 100.0, \"77\": 100.0, \"78\": 100.0, \"79\": 100.0, \"80\": 100.0, \"81\": 100.0, \"82\": 100.0, \"83\": 100.0, \"84\": 100.0, \"85\": 100.0, \"86\": 100.0, \"87\": 100.0, \"88\": 100.0, \"89\": 100.0, \"90\": 100.0, \"91\": 100.0, \"92\": 100.0, \"93\": 100.0, \"94\": 100.0, \"95\": 100.0, \"96\": 100.0, \"97\": 100.0, \"98\": 100.0, \"99\": 100.0, \"100\": 100.0}}', False, False)]\n2023-07-24T13:03:34.535 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:34.536 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=true\n2023-07-24T13:03:34.537 DEBUG::pmlib.api.get_entity_type_id_by_entity_type_name: Retrieving entity type ID by entity type name=1002\n2023-07-24T13:03:34.537 DEBUG::pmlib.api._get_db: Request made to retrieve DB...\n2023-07-24T13:03:34.538 DEBUG::pmlib.api._get_db: Database Type: db2\n2023-07-24T13:03:36.192 DEBUG::pmlib.api._get_db: Retrieved db.model_store.entity_type_id=None\n2023-07-24T13:03:36.193 DEBUG::pmlib.api._get_db: Successfully retrieved DB2 database\n2023-07-24T13:03:36.194 DEBUG::pmlib.api.get_entity_from_metadata: Retrieving entity type name \"1002\" from database entity type metadata\n2023-07-24T13:03:36.194 DEBUG::pmlib.api._get_db: Request made to retrieve DB...\n2023-07-24T13:03:36.195 DEBUG::pmlib.api._get_db: Database Type: db2\n2023-07-24T13:03:37.903 DEBUG::pmlib.api._get_db: Retrieved db.model_store.entity_type_id=None\n2023-07-24T13:03:37.904 DEBUG::pmlib.api._get_db: Successfully retrieved DB2 database\n2023-07-24T13:03:37.905 DEBUG::pmlib.api.get_entity_from_metadata: List of keys retrieved from the entity type metadata: dict_keys([1, 2, 3, 4, 5, 6, 7])\n2023-07-24T13:03:37.906 DEBUG::pmlib.api.get_entity_from_metadata: Found matching entity type in the key 7\n2023-07-24T13:03:37.915 DEBUG::pmlib.api.get_entity_type_id_by_entity_type_name: Found entity type ID of 7 for entity type name of 1002\n2023-07-24T13:03:37.920 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Retrieved entity type ID before saving model: db.model_store.entity_type_id=7\n2023-07-24T13:03:37.935 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785\n2023-07-24T13:03:37.936 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.936 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.946 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json\n", "name": "stdout"}, {"output_type": "stream", "text": "2023-07-24T13:03:37.950 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.951 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.955 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_input.gz\n2023-07-24T13:03:37.958 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator._save_model_df_trace: training_date_range df=\n=========== START DATAFRAME LOG ===========\nshape=(2, 1), \nindex={0: 'int64'}, \ncolumns={'evt_timestamp': datetime64[ns, UTC]}, \nhead(3)=\n                     evt_timestamp\n0 2023-07-24 13:00:04.917807+00:00\n1 2023-07-24 13:03:04.917807+00:00\n=========== END DATAFRAME LOG ===========\n2023-07-24T13:03:37.959 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.959 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.963 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_training_date_range\n2023-07-24T13:03:37.967 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.967 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.972 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_input_after_train_preprocess.gz\n2023-07-24T13:03:37.974 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.974 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.978 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_to_train.gz\n2023-07-24T13:03:37.981 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving model...\n2023-07-24T13:03:37.981 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saving to KPI_MODEL_STORE, pickle_dump=false\n2023-07-24T13:03:37.987 DEBUG::pmlib.degradation_curve.DegradationCurveEstimator.save_model: Saved model to path: apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_output.gz\n2023-07-24T13:03:37.988 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Uploading trained models: uploaded_models={'DegradationCurveEstimator': ['apm/pmi/model/1002/DegradationCurveEstimator/__1690203785', 'apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json']}\n2023-07-24T13:03:37.988 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: kpi_config={'functionName': 'DegradationCurveAssetGroupPipeline', 'enabled': False, 'input': {'asset_group_id': '1002', 'model_pipeline': {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}, 'features_for_training': [':installdate', ':statusdate', ':status']}, 'incremental_summary': False, 'fillna': None, 'fillna_exclude': None, 'dropna': None, 'dropna_exclude': None, 'local_model': False, 'target_pipeline_name': 'DegradationCurveAssetGroupPipeline', 'model_timestamp': {'DegradationCurveEstimator': '1690203785'}}, 'output': {'names': []}, 'backtrack': {'days': 0, 'hours': 0, 'minutes': 0}}\n2023-07-24T13:03:37.989 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Final kpi_config before registering to Monitor: kpi_config={'functionName': 'DegradationCurveAssetGroupPipeline', 'enabled': False, 'input': {'asset_group_id': '1002', 'model_pipeline': {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}, 'features_for_training': [':installdate', ':statusdate', ':status']}, 'incremental_summary': False, 'fillna': None, 'fillna_exclude': None, 'dropna': None, 'dropna_exclude': None, 'local_model': False, 'target_pipeline_name': 'DegradationCurveAssetGroupPipeline', 'model_timestamp': {'DegradationCurveEstimator': '1690203785'}}, 'output': {'names': []}, 'backtrack': {'days': 0, 'hours': 0, 'minutes': 0}}\n2023-07-24T13:03:37.990 DEBUG::pmlib.util.api_request: Making API Request: method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/1002/model?instanceId=masdev, headers={'apmapitoken': '********'}, timeout=300, ssl_verify=False, json={'modelTemplateId': 'DegradationCurveAssetGroupPipeline', 'modelCosPath': {'DegradationCurveEstimator': ['apm/pmi/model/1002/DegradationCurveEstimator/__1690203785', 'apm/pmi/model/1002/DegradationCurveEstimator/__1690203785_json']}, 'instanceName': '1002_DegradationCurveAssetGroupPipeline_2023-07-24T13:03:37.989490', 'instanceDesc': '1002_DegradationCurveAssetGroupPipeline_2023-07-24T13:03:37.989490', 'kpiConfig': {'functionName': 'DegradationCurveAssetGroupPipeline', 'enabled': False, 'input': {'asset_group_id': '1002', 'model_pipeline': {'missing_value_analysis': False, 'statistics_distribution_args': {'distribution_type': 'WEIBULL', 'mean_or_scale': None, 'stddev_or_shape': None}, 'features_for_training': [':installdate', ':statusdate', ':status']}, 'incremental_summary': False, 'fillna': None, 'fillna_exclude': None, 'dropna': None, 'dropna_exclude': None, 'local_model': False, 'target_pipeline_name': 'DegradationCurveAssetGroupPipeline', 'model_timestamp': {'DegradationCurveEstimator': '1690203785'}}, 'output': {'names': []}, 'backtrack': {'days': 0, 'hours': 0, 'minutes': 0}}, 'granularity': [{'name': 'GroupDaily', 'description': 'GroupDaily', 'frequency': 'Daily', 'dataItems': [], 'entityFirst': False}, {'name': 'Hourly', 'description': 'Hourly', 'frequency': 'Hourly', 'dataItems': [], 'entityFirst': True}, {'name': 'GroupHourly', 'description': 'GroupHourly', 'frequency': 'Hourly', 'dataItems': [], 'entityFirst': False}, {'name': 'Minute', 'description': 'Minute summary', 'frequency': 'Minute', 'dataItems': [], 'entityFirst': True}, {'name': 'GroupMinute', 'description': 'GroupMinute', 'frequency': 'Minute', 'dataItems': [], 'entityFirst': False}], 'postProcessing': [], 'publishedOutputs': {}}, session=None, kwargs={}\n2023-07-24T13:03:38.553 DEBUG::pmlib.util.api_request: Received API Response: resp.status_code=200, method=post, url=https://masocp-igki4x-predict-api.mas-masocp-igki4x-predict.svc/ibm/pmi/service/rest/ds/inuqrvb39kbuvc4odt7ntmqr3n1of68ojjjt6o6t/1002/model?instanceId=masdev\n2023-07-24T13:03:38.555 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: <Response [200]>\n2023-07-24T13:03:38.555 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Registed model instance with response: {'modelInstanceId': '78942A87-DA27-4368-BF76-AA603D8B2702', 'message': 'Created', 'status': 0}\n2023-07-24T13:03:38.556 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Registration succeeded. Writing initial prediction results...\n2023-07-24T13:03:38.585 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._validate_checkpoint: entity_type=1002 with entity_type_id=7 does not have any type-level checkpoint yet\n2023-07-24T13:03:38.591 DEBUG::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline._validate_checkpoint: entity_type=1002 with entity_type_id=7 type-level checkpoint inserted\n2023-07-24T13:03:38.592 INFO::pmlib.degradation_curve.DegradationCurveAssetGroupPipeline.register: Registration was successful. New model ID = 78942A87-DA27-4368-BF76-AA603D8B2702\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "'78942A87-DA27-4368-BF76-AA603D8B2702'"}, "metadata": {}}]}, {"metadata": {"id": "7d247a81-2681-45d5-b3b8-9d75c0359988"}, "cell_type": "markdown", "source": "After registration succeeds, you can see this newly trained model instance available for the asset group on IBM Maximo Predict."}, {"metadata": {"id": "977c7f81347046ac8afd3621b7cfe80d"}, "cell_type": "markdown", "source": "# Re-train the model instance"}, {"metadata": {"id": "bac12a1e84294fd381e57fca993bbff5"}, "cell_type": "markdown", "source": "If there is an existing model instance and you want to re-train the model, you need to first unregister the model. You can get the model_instance_id from Health UI. Click \"Predict grouping\" and find the model instance id of your group.\nYou can also use the below API to get the model_instance_id.\nYou need to call group.unregister(predict_curve_instance_id,force=True) to unregister the model first."}, {"metadata": {"id": "03cb8a1337364e5d81fec40ef4af3a76"}, "cell_type": "code", "source": "##This step is to query if any existing predict curve instance associated with the asset group.\n##If any, unregister it firstly.\nimport urllib3\nimport json\npredict_internal_svc=os.getenv('APM_API_BASEURL')[8:]\napm_id=os.getenv('APM_ID')\napm_api_key_dic={}\napm_api_key_dic['apmapitoken']=os.getenv('APM_API_KEY')\npredict_curve_instance_id=None\n\n\nasset_group_id ='1057'\n\n\nquery_url='/ibm/pmi/service/rest/assetgroup/' + asset_group_id +'/model?instanceId='+ apm_id\nc = urllib3.HTTPSConnectionPool(predict_internal_svc, port=443, cert_reqs='CERT_NONE',assert_hostname=False)\n\n#response=c.request('GET', '/ibm/pmi/service/rest/assetgroup/1029/model?instanceId=243d1b41',headers={'apmapitoken':'98mgppjl0ghkbqs9loisri01viennenq9hech8eo'})\nresponse=c.request('GET', query_url, headers=apm_api_key_dic)\nprint(response.data)\nresponse_data_json=json.loads(response.data.decode('utf8'))\n\nfor model_instance in response_data_json['modelInstanceList']:\n    #print(model_instance)\n    modelTemplateName=model_instance.get('modelTemplateDesc',None)\n    #print(modelTemplateName)\n    #print(model_instance.get('modelTemplateDesc',None))\n    if modelTemplateName is not None and modelTemplateName.find('Curve') != -1:\n        #print(modelTemplateName)\n        #print(model_instance)\n        predict_curve_instance_id=model_instance['instanceList'][0]['modelInstanceId']\n        print(predict_curve_instance_id)\n        \n", "execution_count": null, "outputs": []}, {"metadata": {"id": "27d99b1a29024c5db8613b999298e053"}, "cell_type": "code", "source": "if predict_curve_instance_id is not None:\n    group.unregister(predict_curve_instance_id,force=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "32b1031cf4bb4c9aaa5a37876252be1f"}, "cell_type": "code", "source": "from pmlib.degradation_curve import DegradationCurveAssetGroupPipeline\n\ngroup = DegradationCurveAssetGroupPipeline(\n            asset_group_id=asset_group_id, \n            model_pipeline={\n                \n                \"statistics_distribution_args\": {\n                    \"distribution_type\": \"WEIBULL\", \n                    \"mean_or_scale\": None,\n                    \"stddev_or_shape\": None\n                }\n            })", "execution_count": null, "outputs": []}, {"metadata": {"id": "5a1b06757ee4414d8f63ef635bb97f33"}, "cell_type": "code", "source": "df = group.execute()", "execution_count": null, "outputs": []}, {"metadata": {"id": "54e094283d664470808b8a408aa0569d"}, "cell_type": "code", "source": "group.register()", "execution_count": null, "outputs": []}, {"metadata": {"id": "ab711c14-ad79-4a7d-96a8-f5f541391223"}, "cell_type": "markdown", "source": "# Training using CSV file"}, {"metadata": {"id": "123d839e-736a-4736-acee-ae8ee3168464"}, "cell_type": "markdown", "source": "You can train the model instance using the CSV file.\nThe format of the CVS is the following:\n    asset \tsite \tinstalldate \tstatusdate \tstatus\n    The value of status can be 'DECOMMISSIONED' or empty string."}, {"metadata": {"id": "01d21532-385e-4181-8f04-1eda62113932"}, "cell_type": "code", "source": "import types\nimport pandas as pd\ndf_data_1 = pd.read_csv('/project_data/data_asset/trainbrake_asset_attributes_degradation_curve.csv')\ndf_data_1.head()\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "06713a43-b38b-44d3-bce2-a41ed23477ad"}, "cell_type": "code", "source": "asset_group_id='1018'", "execution_count": null, "outputs": []}, {"metadata": {"id": "e8514500-bfdd-4e6a-ae2b-d11b803c6831"}, "cell_type": "code", "source": "from pmlib.degradation_curve import DegradationCurveAssetGroupPipeline\ngroup = DegradationCurveAssetGroupPipeline(\n                    asset_group_id=asset_group_id,\n                    model_pipeline={\n                        'missing_value_analysis': False,  # skip missing value analysis\n                        \n                        'statistics_distribution_args': {\n                            'distribution_type': 'WEIBULL',\n                            'mean_or_scale': None,\n                            'stddev_or_shape': None,\n                        },\n                    },\n                    asset_device_mappings={\n                    'TRAINBRAKE1____-BEDFORD': [], \n                    'TRAINBRAKE2____-BEDFORD': [],\n                    'TRAINBRAKE3____-BEDFORD': [],\n                    'TRAINBRAKE4____-BEDFORD': [],\n                    'TRAINBRAKE5____-BEDFORD': [],\n                    },\n                   \n                    data_substitution={\n                    '': [\n                        {\n                            'df': df_data_1,\n                            'keys': ['asset'],\n                            'columns': ['installdate','statusdate','status'],\n#                             'timestamp': 'datetime'\n                        },\n                    ]}\n                )", "execution_count": null, "outputs": []}, {"metadata": {"id": "c2ec5005-f7e6-48cf-a47b-6d745c0bfbf4"}, "cell_type": "code", "source": "df=group.execute()", "execution_count": null, "outputs": []}, {"metadata": {"id": "0ab200ae-0eea-458e-8141-c401ee17aefb"}, "cell_type": "code", "source": "model_instance_desc='End of Life Curve for group='+asset_group_id\ngroup.register(model_instance_name='End of Life Curve',model_instance_desc=model_instance_desc)", "execution_count": null, "outputs": []}, {"metadata": {"id": "93f77b7d44be46618485f589503fe253"}, "cell_type": "code", "source": "# All time is UTC time, see following example to set schedule to run every 5 minute, every hour, every day, every week, every month\n# minute and second will be ignored. \"2021-04-12 15:12:15\" is same as \"2021-04-12 15:00:00\" in following examples\n#group.enable(enabled=True, schedule={\"starting_at\": \"2021-04-09 15:35:15\", \"every\": \"5min\"})\n#group.enable(enabled=True, schedule={\"starting_at\": \"2021-04-12 15:12:15\", \"every\": \"1H\"})\n#group.enable(enabled=True, schedule={\"starting_at\": \"2021-04-12 15:12:15\", \"every\": \"1D\"})\n#group.enable(enabled=True, schedule={\"starting_at\": \"2021-04-12 15:12:15\", \"every\": \"1W\"})\n#group.enable(enabled=True, schedule={\"starting_at\": \"2021-04-12 15:12:15\", \"every\": \"1M\"})\ngroup.enable(enabled=True, schedule={\"starting_at\": \"2021-04-12 15:12:15\", \"every\": \"5min\"})", "execution_count": null, "outputs": []}, {"metadata": {"id": "d55a285b-e278-4013-86d0-5a1e13f7278c"}, "cell_type": "markdown", "source": "<a id=\"model-template-internals\"></a>\n## Model template internals\n"}, {"metadata": {"id": "eb49aa0d-170c-4358-ae04-5827b2953cb1"}, "cell_type": "markdown", "source": "#### Use case description\n\nThis model deals with computing failure probabilities versus year of a type of asset. Using this model one can answer the questions of the pattern: **What is the failure probability when the asset is N years old ?**\n\n##### Input data from Maximo. The Predictive Maintenance Insights SDK does this part.\n\n+ Assets metadata: installation date and decommission date\n\n##### Output\n\nThe output is a list of the assets' year versus failure probability, which is saved in Cloud Object Storage.\n\n##### Customization points\n\n+ The **`distribution_type`** in cell **`Setup the Model Training Pipeline`** is the distribution type. It should be NORMAL or WEIBULL.\n+ The **`mean_or_scale\"`** and **`stddev_or_shape`** are the parameters for NORMAL or WEIBULL distribution. If not specifed, it uses assets' metadata to calculate the failure probability curve. Otherwise, it generates the curve with the specified parameters.\n+ Failure probability curve algorithm (**`DegradationCurveEstimator`** class in the following model template code)\n+ Model pipeline stages control (**`DegradationCurveAssetGroupPipeline`** class in the following model template code)\n\n##### Model workflow and description (from **`degradation_curve_model.py`** in the Predictive Maintenance Insights SDK)\n\n+ Step 1: Collect data of in-service years and retired years of the specific assets\n+ Step 2: Calculate:\n                  Retired (died) one: Age = \u201cRetired year\u201d \u2013 \u201cIn-service year\u201d\n                  Normal one: Age = \u201cCurrent year\u201d \u2013 \u201cIn-service year\u201d\n                  Exposed number: how many reactors service longer than the age\n+ Step 3: Calculate cumulative failure probability (CFP) table:\n                  Failure Probability (FP) = retired number / exposed number\n                  Cumulative FP (k) = Cumulative FP (k-1) + FP (k) \n                  Z values based on Cumulative FP\n                  Create a table following the form like : | Age | Cumulative Failure Probability | z |\n+ Step 4: Estimate the mean life and the standard deviation of the normal distribution\n+ Step 5: Generate the NORMAL degradation curve\n+ Step 6: based on CFP table to get survival table like: | Age | Survival Probability |\n+ Step 7: Construct maximum likelihood function\n+ Step 8: Calculate initial shape and scale parameters for WEIBULL distribution\n+ Step 9: Use gradient-decent method to get optimal shape and scale parameters"}, {"metadata": {"id": "866de11e-ce46-4825-b6fb-a2f4da48e792"}, "cell_type": "code", "source": "class DegradationCurveEstimator(BaseEstimator):\n    def __init__(self, features, targets, predictions, statistics_distribution_args=None, **kwargs):\n        super().__init__(features, targets, predictions, **kwargs)\n        self.statistics_distribution_args = statistics_distribution_args\n        self.installdate = kwargs['features_for_training'][0]\n        self.decommissiondate = kwargs['features_for_training'][1]\n\n    def train_model(self, df):\n        # parse statistics_distribution_args\n        distribution_type = self.statistics_distribution_args[\"distribution_type\"]\n        mean_or_scale = self.statistics_distribution_args[\"mean_or_scale\"]\n        stddev_or_shape = self.statistics_distribution_args[\"stddev_or_shape\"]\n\n        # distribution should not be none\n        if distribution_type is None:\n            raise('distribution_type should be NORMAL or WEIBULL')\n        \n        degradation_curve_pipline = DegradationCurve(distribution_type, mean_or_scale, stddev_or_shape, self.installdate, self.decommissiondate)\n        # using sample data to test degradation curve calculation\n        #df_curve_training_data = degradation_curve_pipline.sample_data()\n        # use real data from DB2\n        df_curve_training_data = df\n        self.logger.debug('df_curve_training_data=\\n%s' % df_curve_training_data.head())\n\n        final_degradation_curve = degradation_curve_pipline.fit(df_curve_training_data, distribution_type, mean_or_scale, stddev_or_shape)\n        degradation_curve_model = dict()\n        #degradation_curve_model[\"target\"] =  \"degradation_curve\"\n        degradation_curve_model[\"final_degradation_curve\"] =  final_degradation_curve\n\n        return degradation_curve_model\n    \n    def get_model_extra(self, new_model, model_path):\n        extras = []\n\n        model_json_path = model_path + '_json'\n        extras.append((model_json_path, json.dumps(new_model), False, False)) # no pickle dump, not binary\n\n        self.logger.debug('extras=%s' % str(extras))\n\n        return extras\n\n\nclass DegradationCurveAssetGroupPipeline(AssetGroupPipeline):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n        self.model_template_name = 'Failure Probability Curve'\n\n        self.fillna = None\n        self.dropna = None\n\n    def prepare_execute(self, pipeline, model_config):\n        pipeline.add_stage(DegradationCurveEstimator(**model_config))\n\n    @staticmethod\n    def generate_sample_data(**kwargs):\n        return generate_degradation_curve_data(**kwargs)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2eac9f49-7436-40a6-8115-8a18a2c665b9"}, "cell_type": "code", "source": "class DegradationCurve:\n    '''\n    The degradation curve supports NORMAL and WEIBULL distributions\n    distribution_type: the distribution type, NORMAL or WEIBULL\n    mean_or_scale: the mean value of NORMAL or the scale value of WEIBULL\n    stddev_or_shape: the standard deviation value of NORMAL or the shape value of WEIBULL\n    '''\n\n    @classmethod\n    def metadata(cls):\n        return {\n            'name': cls.__name__,\n            'moduleAndTargetName': '%s.%s' % (cls.__module__, cls.__name__),\n            'category': 'TRANSFORMER',\n            'description': 'DegradationCurve',\n            'input': [\n            ],\n            'output': [\n            ],\n            'tags': [\n                'EVENT'\n            ]\n        }\n\n    def __init__(self, data_items, statistics_distribution_args, degradation_curve, installdate, decommissiondate):\n        self.logger = logging.getLogger('analytics_service.%s.%s' % (self.__module__, self.__class__.__name__))\n        self.data_items = data_items\n        self.statistics_distribution_args = statistics_distribution_args\n        self.degradation_curve = degradation_curve\n        self.installdate = installdate\n        self.decommissiondate = decommissiondate\n\n    def execute (self, df):\n        self.logger.debug('input_df=\\n%s' % df.head())\n\n        df_original = df\n\n        # pick only needed columns for scoring \n        df = df[list(set(self.data_items) - set(df.index.names))]\n        self.logger.debug('input_df_pick_need_columns=\\n%s' % df.head())\n\n        sources_not_in_column=df.index.names\n        df = df.reset_index()\n\n        # parse statistics_distribution_args\n        distribution_type = self.statistics_distribution_args[\"distribution_type\"]\n        mean_or_scale = self.statistics_distribution_args[\"mean_or_scale\"]\n        stddev_or_shape = self.statistics_distribution_args[\"stddev_or_shape\"]\n\n        # distribution should not be none\n        if distribution_type is None:\n            raise('distribution_type should be NORMAL or WEIBULL')\n\n        # using sample data to test degradation curve calculation\n        df_curve_training_data = self.sample_data()\n        self.logger.debug('df_curve_training_data=\\n%s' % df_curve_training_data.head())\n\n        # fit the degradation curve\n        df_score = df.astype({self._entity_type._timestamp: 'datetime64[ms]'})[[self._entity_type._df_index_entity_id, self._entity_type._timestamp]].copy()\n        final_degradation_curve = self.fit(df_curve_training_data, distribution_type, mean_or_scale, stddev_or_shape)\n        df_score[self.degradation_curve] = str(final_degradation_curve).strip('[]')\n        self.logger.debug('df_score=\\n%s' % df.head())\n\n        df = df_original.merge(df_score, how='left', left_index=True, right_on=[self._entity_type._df_index_entity_id, self._entity_type._timestamp], sort=False)\n        df = df.set_index(keys=sources_not_in_column)\n        self.logger.debug('df_final=\\n%s' % df.head())\n\n        return df\n\n\n    def fit(self, df_curve_training_data, distribution_type, mean_or_scale, stddev_or_shape):\n        self.logger.debug('initial mean_or_scale=%s' % mean_or_scale)\n        self.logger.debug('initial stddev_or_shape=%s' % stddev_or_shape)\n\n        df_curve_training_data[self.installdate] = pd.to_datetime(df_curve_training_data[self.installdate]).dt.year\n        df_curve_training_data[self.decommissiondate] = np.where(pd.notna(df_curve_training_data[self.decommissiondate]), pd.to_datetime(df_curve_training_data[self.decommissiondate]).dt.year, -1)\n        df_curve_training_data = df_curve_training_data.astype({self.installdate: int, self.decommissiondate: int})\n        self.logger.debug('df_curve_training_data=%s' % log_df_info(df_curve_training_data, head=-1))\n\n        # initialize parameter\n        mean_or_scale_final = 0.0\n        stddev_or_shape_final = 0.0\n\n        # if mean value and stddev value are specified by user, use them to generate the degradation curve\n        if mean_or_scale is not None and stddev_or_shape is not None:\n            self.logger.debug('generate degradation curve with user defined parameters')\n            mean_or_scale_final = float(mean_or_scale)\n            stddev_or_shape_final = float(stddev_or_shape)\n        else:\n            # generate NORMAL distribution by input data\n            if distribution_type == 'NORMAL':\n                self.logger.debug('calculate the mean value and stddev value for normal distribution...')\n                mean_or_scale_final, stddev_or_shape_final, df_cfp = self.generate_normal_distribution(df_curve_training_data)\n                self.logger.debug('calculate done')\n\n            # generate WEIBULL distribution by input data\n            if distribution_type == 'WEIBULL':   \n                self.logger.debug('calculate the scale value and shape value for normal distribution...')\n                mean_or_scale_NORMAL, stddev_or_shape_NORMAL, df_cfp = self.generate_normal_distribution(df_curve_training_data)\n                mean_or_scale_final, stddev_or_shape_final = self.generate_weibull_distribution(mean_or_scale_NORMAL, stddev_or_shape_NORMAL, df_cfp)\n                self.logger.debug('calculate done')\n\n        # return the final curve\n        return self.generate_final_curve(distribution_type, mean_or_scale_final, stddev_or_shape_final)\n                \n    def generate_normal_distribution(self, df_curve_training_data):\n        # df_curve_training_data: [assetId, installationDate, removeDate]\n        # step1. pre-processing\n        date_service = df_curve_training_data[self.decommissiondate] - df_curve_training_data[self.installdate]\n        df_curve_training_data['retired_flag'] = np.where(date_service>=0, 1, 0)\n        df_curve_training_data['date_service'] = np.where(date_service>=0, date_service, 2000 - df_curve_training_data[self.installdate])  # should be datetime.datetime.now().year, 2000 as test year for sample data\n        self.logger.debug('df_curve_training_data_pre_processing=\\n%s' % df_curve_training_data)\n\n        # step2. calculate the exposed table\n        df_exposed_table = df_curve_training_data.groupby(['date_service']).agg({'retired_flag':'sum', 'date_service':'count'})\n        df_exposed_table.rename(columns={'date_service': 'pre_exposed_number'}, inplace=True)\n        df_exposed_table.sort_index(inplace=True, ascending=False)\n        \n        df_exposed_table['exposed_number'] = df_exposed_table.pre_exposed_number.cumsum()\n        del df_exposed_table['pre_exposed_number']\n        df_exposed_table = df_exposed_table.reset_index()\n        df_exposed_table.rename(columns={'retired_flag':'retired_number', 'date_service':'age'}, inplace=True)\n        self.logger.debug('df_exposed_table=\\n%s' % df_exposed_table.head(200))\n\n        # step3. calculate cumulative failure probablity (cfp) table\n        # df_exposed_table: [age, retired_number, exposed_number]\n        max_age = df_exposed_table['age'].max()\n        \n        \n        \n        max_age_idx = df_exposed_table[df_exposed_table['age'] == max_age].index.values.astype(int)[0] # 0, first row\n        #print('------------ ' + str(max_age_idx))\n        a1 = (df_exposed_table.loc[max_age_idx, 'retired_number']) \n        a2 = (df_exposed_table.loc[max_age_idx, 'exposed_number'])\n        if (a1 == a2) : \n            print (\"Number of exposed assets = number of retired assets in max_age, meaning all the asset observed failed at max_age\")\n            # If max_age-1 exist in the df, drop the max_age row as outlier - some asset may survive after max_age year, we just need enough time to observe.\n            # If max_age-1 doesn't exist in the df, modify max_age row to max_age-1\n            if ( (max_age-1) == df_exposed_table.loc[max_age_idx+1, 'age'] ):\n                #print (\"max_age-1 is in !!! drop max_age row\")\n                df_exposed_table = df_exposed_table.drop(df_exposed_table.index[max_age_idx]) \n            else:    \n                df_exposed_table.loc[max_age_idx, 'retired_number'] = 0\n                df_exposed_table.loc[max_age_idx, 'age'] = max_age - 1\n        #print('df_exposed_table 2 =\\n%s' % df_exposed_table.head(200))        \n        #print('------------')\n        \n        \n        \n        df_cfp = df_exposed_table[df_exposed_table['retired_number'] !=0]\n        self.logger.debug('df_cfp_input=\\n%s' % df_cfp.head())\n        df_cfp['pre_cumulative_probability'] = df_cfp['retired_number'] / df_cfp['exposed_number']\n        cfp_first_line = [df_cfp['age'].min()-1, -1, -1, 0.001]\n        cfp_last_line = [max_age, -1, -1, 0]\n        df_cfp = pd.DataFrame(np.array([cfp_first_line, cfp_last_line]), columns=['age', 'retired_number', 'exposed_number', 'pre_cumulative_probability']).append(df_cfp, ignore_index=True)\n        df_cfp.sort_values('age', inplace=True)\n        df_cfp['cumulative_probability'] = df_cfp.pre_cumulative_probability.cumsum()\n        df_cfp['z'] = norm.ppf(df_cfp['cumulative_probability'])\n        self.logger.debug('df_cfp=\\n%s' % df_cfp.head(200))\n\n        # step4. estimate optimal mean value and stddev value\n        #df_cfp: [age, retired_number, exposed_number, pre_cumulative_probability, cumulative_probability, z]\n        age_mean = df_cfp['age'].mean()\n        z_mean = df_cfp['z'].mean()\n        df_cfp['pre_Szx'] = (df_cfp['z'] - df_cfp['z'].mean()) * (df_cfp['age'] - df_cfp['age'].mean())\n        df_cfp['pre_Szz'] = (df_cfp['z'] - df_cfp['z'].mean()) * (df_cfp['z'] - df_cfp['z'].mean())\n        Szx = df_cfp['pre_Szx'].sum()\n        Szz = df_cfp['pre_Szz'].sum()\n        stddev_or_shape_NORMAL = Szx / Szz\n        mean_or_scale_NORMAL = age_mean - stddev_or_shape_NORMAL * z_mean\n        self.logger.debug('mean_or_scale_NORMAL=\\n%s' % mean_or_scale_NORMAL)\n        self.logger.debug('stddev_or_shape_NORMAL=\\n%s' % stddev_or_shape_NORMAL)\n        return mean_or_scale_NORMAL, stddev_or_shape_NORMAL, df_cfp\n\n    def generate_weibull_distribution(self, mean_or_scale_NORMAL, stddev_or_shape_NORMAL, df_cfp):\n        # step1. get the survival table based on cfp table\n        self.logger.debug('WEIBULL_input_df_cfp=\\n%s' % df_cfp)\n        df_cfp['survival_probablity'] = np.where(df_cfp['age'] == df_cfp['age'].min(), 1, 1 - df_cfp['cumulative_probability'])\n        df_cfp_survival = df_cfp.reset_index()\n        self.logger.debug('df_cfp_survival=\\n%s' % df_cfp_survival)\n\n        # step2. get initial alpha (scale) and beta (shape)\n        # initial beta\n        initial_beta = 0.0\n        beta_criteia = sys.float_info.max\n        for beta in np.arange(0.1, 100, 0.001):\n            beta_estimation = ((1+2/beta)**(0.5+2/beta) * math.exp(-(1+2/beta)) * (1 + 1/12/(1+2/beta))) \\\n                                      / ((1+1/beta)**(1+2/beta) * math.exp(-(2+2/beta)) * (1+1/12/(1+1/beta))**2 * math.sqrt(2*math.pi)) \n            beta_criteia_now = abs(beta_estimation - (1 + stddev_or_shape_NORMAL ** 2 / mean_or_scale_NORMAL ** 2))\n            if beta_criteia_now < beta_criteia:\n                beta_criteia = beta_criteia_now\n                initial_beta = beta\n        self.logger.debug('initial_beta=\\n%s' % initial_beta)\n        # initial alpha\n        initial_alpha = math.sqrt(stddev_or_shape_NORMAL**2 / ( math.sqrt(2*math.pi)*((1+2/initial_beta)**(0.5+2/initial_beta) \\\n                                    * math.exp(-(1+2/initial_beta)) * (1 + 1/12/(1+2/initial_beta))) - (2*math.pi*(1+1/initial_beta)**(1+2/initial_beta) \\\n                                    * math.exp(-(2+2/initial_beta)) * (1+1/12/(1+1/initial_beta))**2) ) )\n        self.logger.debug('initial_alpha=\\n%s' % initial_alpha)\n\n        # step3. use gradient decent method to search optimal alpha and beta\n        # initialization\n        age_array = df_cfp_survival['age'].tolist()\n        SP_array = df_cfp_survival['survival_probablity'].tolist() # SP for survivial probability\n        rowcount = len(age_array)\n        alpha = initial_alpha # initial value of alpha\n        beta = initial_beta # initial value of beta\n        eps = 0.01 # step length\n        precision = 0.003 # stop criteria, it is not set too small to avoid overfitting\n        performance_objective = 0 # performance object function\n        gradient_alpha = 0\n        gradient_beta = 0\n        err_objective_iter = 0\n        gradient_alpha_iter = 0\n        gradient_beta_iter = 0\n        \n        # initial value for performance objective function\n        for i in range(0,rowcount):       \n            err_objective_iter = err_objective_iter + math.pow(math.log(SP_array[i]) + math.pow((age_array[i] / alpha), beta),2) \n        performance_objective = err_objective_iter\n        err_objective_iter = 0\n        self.logger.debug(\"the init performance objective function vaule is: \" + str(performance_objective))\n\n        # main part of gradient decent\n        iteration = 0\n        while abs(performance_objective) > precision:          \n            for i in range(0,rowcount):\n                err_objective_iter = err_objective_iter + math.pow(math.log(SP_array[i]) + math.pow((age_array[i] / alpha), beta), 2)\n                gradient_alpha_iter = gradient_alpha_iter + 2 * (math.log(SP_array[i]) + math.pow((age_array[i] / alpha), beta)) * beta * math.pow((age_array[i] / alpha), beta-1) * (-age_array[i] / alpha / alpha)\n                gradient_beta_iter = gradient_beta_iter + 2 * (math.log(SP_array[i]) + math.pow((age_array[i] / alpha), beta)) * math.pow((age_array[i] / alpha), beta) * math.log(age_array[i] / alpha)\n            gradient_alpha = gradient_alpha_iter\n            gradient_alpha_iter = 0\n            gradient_beta = gradient_beta_iter\n            gradient_beta_iter = 0\n            performance_objective = err_objective_iter\n            performance_objective_iter = 0\n            alpha = alpha - eps * gradient_alpha # gradient decent\n            beta = beta - eps * gradient_beta # gradient decent          \n            iteration = iteration + 1\n            #print(iteration)\n            if iteration == 1000 :\n                break\n        self.logger.debug(\"the optimal alpha is \" + str(alpha))\n        self.logger.debug(\"the optimal beta is \" + str(beta))\n\n        mean_or_scale_WEIBULL = alpha\n        stddev_or_shape_WEIBULL = beta\n        self.logger.debug('mean_or_scale_WEIBULL=\\n%s' % mean_or_scale_WEIBULL)\n        self.logger.debug('stddev_or_shape_WEIBULL=\\n%s' % stddev_or_shape_WEIBULL)\n        return mean_or_scale_WEIBULL, stddev_or_shape_WEIBULL\n\n    def generate_final_curve(self, distribution_type, mean_or_scale_final, stddev_or_shape_final):\n        self.logger.debug('generate final degradation curve')\n        #final_degradation_curve = []\n        final_degradation_curve = dict()\n        \n        if distribution_type == 'WEIBULL':\n            for age in range(0, 101, 1):\n                failure_probablity_for_age = (1- math.exp(-((age / mean_or_scale_final) ** stddev_or_shape_final))) * 100  #cumulative density function of WEIBULL\n                #final_degradation_curve.append([age, failure_probablity_for_age])\n                final_degradation_curve[age] = failure_probablity_for_age\n                \n        elif distribution_type == 'NORMAL':\n            for age in range(0, 101, 1):\n                failure_probablity_for_age = norm(mean_or_scale_final, stddev_or_shape_final).cdf(age)  #cumulative density function of NORMAL\n                #final_degradation_curve.append([(]age, failure_probablity_for_age])\n                final_degradation_curve[age] = failure_probablity_for_age\n        else:\n            raise('distribution type is invalid')\n        self.logger.debug('final_degradation_curve=\\n%s' % final_degradation_curve)    \n        # here return the list curve, to consider both old and new pipeline mode\n        #return str(final_degradation_curve).strip('[]')\n        return final_degradation_curve", "execution_count": null, "outputs": []}, {"metadata": {"collapsed": true, "id": "54bd495d-3ee0-4a6e-8b8c-25cbde77181e"}, "cell_type": "markdown", "source": "## How to override base class\nIf you want to customize some functions in the model template, you can just override the function. For example **`DegradationCurveEstimator(BaseEstimator)`**, It is based on the base class **`BaseEstimator`** you can:\n+ override the existing method in **`BaseEstimator`**, like **`train_model`** method\n+ add new function to configure the algorithm\n\n    def train_model(self, df):\n        # parse statistics_distribution_args\n        distribution_type = self.statistics_distribution_args[\"distribution_type\"]\n        mean_or_scale = self.statistics_distribution_args[\"mean_or_scale\"]\n        stddev_or_shape = self.statistics_distribution_args[\"stddev_or_shape\"]\n\n        # distribution should not be none\n        if distribution_type is None:\n            raise('distribution_type should be NORMAL or WEIBULL')\n        \n        degradation_curve_pipline = DegradationCurve(distribution_type, mean_or_scale, stddev_or_shape, self.installdate, self.decommissiondate)\n        # using sample data to test degradation curve calculation\n        #df_curve_training_data = degradation_curve_pipline.sample_data()\n        # use real data from DB2\n        df_curve_training_data = df\n        self.logger.debug('df_curve_training_data=\\n%s' % df_curve_training_data.head())\n\n        final_degradation_curve = degradation_curve_pipline.fit(df_curve_training_data, distribution_type, mean_or_scale, stddev_or_shape)\n        degradation_curve_model = dict()\n        #degradation_curve_model[\"target\"] =  \"degradation_curve\"\n        degradation_curve_model[\"final_degradation_curve\"] =  final_degradation_curve\n\n        return degradation_curve_model"}, {"metadata": {"id": "7b032af2-ec99-4721-9506-8fbc66b621e1"}, "cell_type": "markdown", "source": "#### Base class `BaseEstimator`"}, {"metadata": {"id": "0b494d22-6ffc-49fe-b74f-5ab3192300e8"}, "cell_type": "code", "source": "class BaseEstimator(BaseEstimatorFunction):\n    '''Base class for estimators, supporting training/prediction/scoring.\n\n    Note that though the AS base class supports multiple targets per estimator, we \n    are using a single target per estimator for now. So this class assumes that the \n    given targets and predictions are always one-element arrays. Also, when \n    prediction is not needed, the passed-in predictions should be an array of one \n    element 'None'.\n    '''\n    def __init__(self, features, targets, predictions, features_for_training=None, label_names=None, **kwargs):\n        super().__init__(features, targets, predictions)\n        self.models = dict()\n        self.model_extras = defaultdict(list)\n        self.logger = get_logger(self)\n        self.features_for_training = features_for_training\n        self.label_names = label_names\n        self.local_model = True\n        self.model_timestamp = None\n        self.training_timestamp = None\n\n    def get_model_name(self, target_name, suffix=None):\n        if suffix is None:\n            suffix = self.model_timestamp\n        return self.generate_model_name(target_name=target_name, prefix=None, suffix=suffix)\n    \n    def generate_model_name(self, target_name, prefix=None, suffix=None):\n        name = ['apm', 'pmi', 'model']\n\n        if prefix is not None:\n            if isinstance(prefix, str):\n                prefix = [prefix]\n            if len(prefix) > 0:\n                name += prefix\n        name.extend([self._entity_type.logical_name, self.name, target_name])\n        name = '/'.join(name)\n\n        if suffix is not None:\n            if isinstance(suffix, datetime):\n                name += '_' + str(calendar.timegm(suffix.timetuple()))\n            else:\n                name += '_' + str(suffix)\n\n        return name\n\n    def _get_target_name(self):\n        return '_' if (self.predictions is None or len(self.predictions) == 0) else self.predictions[0]\n\n    def _load_model(self, bucket):\n        model_name = self.get_model_name(target_name=self._get_target_name()) # load with default suffix timestamp\n        return (model_name, self.load_model(model_name, bucket, self.local_model))\n\n    def load_model(self, model_path, bucket, local):\n        if local:\n            # local FS\n            model = None\n            try:\n                with open(model_path, mode='rb') as file:\n                    model = file.read()\n            except FileNotFoundError as e:\n                pass\n            return pickle.loads(model) if model is not None else None\n        else:\n            return self._entity_type.db.cos_load(filename=model_path, bucket=bucket, binary=True)\n\n    def _save_model(self, bucket, new_model, suffix=None, local=True):\n        filename = self.get_model_name(target_name=self._get_target_name(), suffix=suffix) # save with explicity suffix timestamp set\n\n        objects = [(filename, new_model, True, True)] # model itself always pickle dumped and binary\n        extras = self.get_model_extra(new_model, filename)\n        objects.extend(extras)\n        for fname, obj, picket_dump, binary in objects:\n            self.save_model(obj, fname, bucket, picket_dump, binary, local)\n\n        # add model to internal list for prediction usage\n        self.models[filename] = new_model\n        if len(extras) > 0:\n            self.model_extras[filename].extend(extras)\n\n    def save_model(self, new_model, model_path, bucket, pickle_dump, binary, local):\n        if local:\n            mode = 'w'\n            if pickle_dump:\n                new_model = pickle.dumps(new_model)\n            if binary:\n                mode += 'b'\n\n            try:\n                mkdirp(model_path)\n            except:\n                pass\n            with open(model_path, mode=mode) as file:\n                file.write(new_model)\n        else:\n            try:\n                if pickle_dump:\n                    self._entity_type.db.cos_save(persisted_object=new_model, filename=model_path, bucket=bucket, binary=binary)\n                else:\n                    # work-around to be able to not pickle save to cos\n                    ret = self._entity_type.db.cos_client._cos_api_request('PUT', bucket=bucket, key=model_path, payload=new_model, binary=binary)\n                    if ret is None:\n                        self.logger.warn('Not able to PUT %s to COS bucket %s', (model_path, bucket))\n            except requests.exceptions.ReadTimeout as err:\n                self.logger.warn('timeout saving %s to cos: %s' % (model_path, err))\n\n        self.logger.debug('saved %s' % model_path)\n\n    def get_model_extra(self, new_model, model_path):\n        '''Return extra objects to be saved along with the model as a list of (path, object, pickle_dump, binary) tuples.\n\n        A normal estimator only has one model object to be saved to Cloud Object Storage. Some estimtors might want to save \n        other objects, possibly caching/deriving from the model object, for other usage. You can override \n        this method to return a list of such additional objects, in the form of (cos_path, object, pickle_dump, binary) tuple.\n\n        It is recommended that you construct your extra object cos_path based on the given model_path, with \n        different suffix appended.\n        '''\n        return []\n\n    def get_models_for_training(self, db, df, bucket=None):\n        model_name, model = self._load_model(bucket=bucket)\n\n        if model is not None:\n            self.models[model_name] = model\n            return []\n        else:\n            return [model]\n\n    def get_models_for_predict(self, db, bucket=None):\n        if len(self.predictions) == 0 or self.predictions[0] is None:\n            return []\n        else:\n            return list(self.models.values())\n\n    def conform_index(self,df,entity_id_col = None, timestamp_col = None):\n        # workaround for avoiding base class adding columns\n        return df\n\n    def add_training_preprocessor(self, stage):\n        self.add_preprocessor(stage)\n\n    def execute_training_preprocessing(self, df):\n        if len(self._preprocessors) == 0:\n            return df\n        else:\n            return super().execute_preprocessing(df)\n\n    def get_df_for_training(self, df):\n        features = [] + self.features\n        if self.features_for_training is not None:\n            features.extend(self.features_for_training)\n\n        df = df[features]\n        df = df.reset_index(drop=True)\n\n        return df\n\n    def execute_train_test_split(self,df):\n        # TODO disable splitting for now\n        return (df, None)\n\n    def get_df_for_prediction(self, df):\n        df_for_prediction = df[self.features]\n        self.logger.debug('df_for_prediction: %s' % log_df_info(df_for_prediction, head=5))\n        # self.logger.debug('df_for_prediction: %s' % str(df_for_prediction.isna().any(axis='columns')))\n        # df_for_prediction = df_for_prediction.dropna()\n        # self.logger.debug('df_for_prediction_dropna: %s' % log_df_info(df_for_prediction, head=5))\n        return df_for_prediction\n\n    def predict(self, model, df):\n        return list(zip(model.predict(df), model.predict_proba(df))) if model is not None else None\n\n    def get_prediction_result_value_index(self):\n        raise RuntimeError('required but not implemented')\n\n    def process_prediction_result(self, df, prediction_result, model):\n        self.logger.debug('prediction_result_length=%d, prediction_result=%s' % (len(prediction_result), str(prediction_result[:10])))\n\n        if prediction_result is None:\n            df[self.predictions[0]] = None\n\n            self.logger.debug('No suitable model found. Created null predictions')\n        else:\n            for idx in self.get_prediction_result_value_index():\n                if not all([isinstance(p, (tuple, list, np.ndarray)) for p in prediction_result]):\n                    break\n\n                prediction_result = [p[idx] for p in prediction_result]\n\n            df[self.predictions[0]] = prediction_result\n\n            self.logger.debug('final_prediction_result_length=%d, final_prediction_result=%s' % (len(prediction_result), str(prediction_result[:10])))\n\n        return df\n\n    def execute(self, df=None):\n        self.logger.debug('df_input: %s' % log_df_info(df, head=5))\n\n        self.logger.debug('self.model_timestamp=%s' % self.model_timestamp)\n\n        db = self._entity_type.db\n        bucket = self.get_bucket_name()\n\n        self.training_timestamp = None\n\n        # transform incoming data using any preprocessors\n        # include whatever preprocessing stages are required by implementing a set_preprocessors method\n        required_models = self.get_models_for_training(db=db, df=df, bucket=bucket)\n        if len(required_models) > 0:   \n            # Training\n\n            # only do preprocessing and splitting once\n            df_train = self.execute_training_preprocessing(df)\n            df_train = self.get_df_for_training(df_train)\n            self.logger.debug('df_train: %s' % log_df_info(df_train, head=5))\n            # df_train, df_test = self.execute_train_test_split(df_train)\n\n            for model in required_models:\n                self.logger.info('training model: %s' % model) \n\n                new_model = self.train_model(df_train)\n\n                self.training_timestamp = str(calendar.timegm(datetime.utcnow().timetuple()))\n\n                # TODO add evaluation of the new model here, before saving it\n                # if df_test is not None:\n                #     new_model.test(df_test)                \n                #     self.evaluate_and_write_model(new_model = new_model,\n                #                                   current_model = model,\n                #                                   db = db,\n                #                                   bucket=bucket)\n\n                self._save_model(bucket=bucket, new_model=new_model, suffix=self.training_timestamp, local=self.local_model)\n\n                # switch to the new one just trained\n                self.model_timestamp = self.training_timestamp\n        elif self.model_timestamp is not None:\n            self.training_timestamp = self.model_timestamp\n\n        # Predictions\n\n        df_for_prediction = None\n        for idx, model in enumerate(self.get_models_for_predict(db=db, bucket=bucket)):        \n            # TODO deal with multiple predictions\n            if df_for_prediction is None:\n                df_for_prediction = self.get_df_for_prediction(df)\n            df = self.process_prediction_result(df, self.predict(model, df_for_prediction), model)\n\n        if df_for_prediction is None:\n            # no prediction needed, return empty df\n            df = df[[]]\n\n        self.logger.debug('df_final: %s' % log_df_info(df, head=5))\n\n        return df", "execution_count": null, "outputs": []}, {"metadata": {"id": "5605fc88-dbfd-4f9e-a97c-3910df59f299"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}